---
title: "Tema 1: Ciencia de datos y la era del Big Data"
author: "Pedro J. P√©rez (pedro.j.perez@uv.es). Universitat de Val√®ncia"
date: "Agosto de 2019 (actualizado el `r format(Sys.time(), '%d-%m-%Y')`)"
output:
  html_document:
    css: !expr here::here("assets", "styles_pjp.css") #-https://stackoverflow.com/questions/56681879/how-to-use-here-for-paths-to-css-before-body-and-after-bod
    theme: paper
    highlight: textmate 
    toc: true
    toc_depth: 3 
    toc_float: 
      collapsed: true
      smooth_scroll: true
    self_contained: true
    number_sections: false
    includes:
      after_body: !expr here::here("assets", "footer.html") 
      in_header: 
        - !expr here::here("assets", "google-analytics.html") 
        - !expr here::here("assets", "favicon-sol.html")
    #code_folding: show
    df_print: kable
    code_download: true
editor_options: 
  chunk_output_type: console
#bibliography: "`r here::here('assets', 'biblio.bib')`"  #- joooder. single quotes https://community.rstudio.com/t/use-here-here-function-in-yaml-option/18667/9
---

```{r, include = FALSE}
library(tidyverse)
```

```{r chunk-setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE, 
                      #results = "hold",
                      cache = FALSE, cache.path = "/caches/", comment = "#>",
                      #fig.width = 7, #fig.height= 7,   
                      #out.width = 7, out.height = 7,
                      collapse = TRUE,  fig.show = "hold",
                      fig.asp = 7/9, out.width = "60%", fig.align = "center")

#- para mejorar los gr√°ficos, bueno en realidad para que se vean igual en distintos SO
#- https://www.jumpingrivers.com/blog/r-knitr-markdown-png-pdf-graphics/
knitr::opts_chunk$set(dev = "png", dev.args = list(type = "cairo-png"))
```

```{r options-setup, include = FALSE}
options(scipen = 999) #- para quitar la notaci√≥n cient√≠fica
options("yaml.eval.expr" = TRUE) #- https://github.com/viking/r-yaml/issues/47  (lo puse x el pb con el warning) En realidad creo que mejor ser√≠a ponerlo en RProfile
```

```{r klippy, echo = FALSE}
klippy::klippy(position = c("top", "right")) #- remotes::install_github("rlesur/klippy")
```


```{r, include = FALSE}
options(htmltools.dir.version = FALSE)
#knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE, echo=FALSE, out.width = "85%")
library(metathis)
meta() %>% meta_name("github-repo" = "perezp44/intro-ds-20-21-web") %>% 
  meta_social(
    title = "Ciencia de datos y la era del Big Data",
    description = paste(
      "Se presentan conceptos e ideas como: Ciencia de datos, Big Data, Inteligencia Artificial, Machine Learning y Deep Learning.",
      "Se muestra la necesidad de la programaci√≥n en la ciencia de datos y la ciencia y an√°lisis reproducibles.",
      "Se destaca el papel del sofware libre en la ciencia y an√°lisis reproducibles y el porqu√© de usar R durante el curso"),
    url = "https://perezp44.github.io/intro-ds-20-21-web/tutoriales/tt_01_introduccion.html",
    og_type = "website",
    og_author = "Pedro J. P√©rez"
  )
```




-----------------



El objetivo principal del curso es aprender un poco, todo lo que podamos, sobre una nueva disciplina: Ciencia de datos o Data Science. En concreto, nos centraremos en aprender a manejar y analizar datos utilizando una herramienta profesional como R.  En el tema 2 hablaremos y utilizaremos intensivamente R, de momento nos sobra con se√±alar que R es un programa inform√°tico, m√°s bien un entorno, con el que hacer an√°lisis de datos (o ciencia de datos), pero R tambi√©n es un lenguaje de programaci√≥n. Lo veremos!! 

Pero antes de empezar el cuerpo principal del curso, voy a tratar de explicar en este tema introductorio qu√© significan t√©rminos que todos hab√©is o√≠do como: Big Data, Inteligencia Artificial (IA), Machine Learning (ML), algoritmos, redes neuronales, etc... etc... Puff!!! Muchas cosas, pero ... paso a paso, ["bird by bird"](https://www.bookdepository.com/Bird-By-Bird-Anne-Lamott/9780385480017).


## 1. ¬øQu√© es esto de la era del Big Data?

Pues no os voy a enga√±ar, la principal raz√≥n de la presencia del t√©rmino "Big Data" en el t√≠tulo del curso es que me parec√≠a que como el t√≠tulo comienza con "Programaci√≥n y manejo de datos ...", es posible que nadie se apuntase al curso, as√≠ que hab√≠a que a√±adir al t√≠tulo un t√©rmino de moda y un poco misterioso. ¬øEstrategia de marketing? Un poco s√≠, pero en realidad todos los cursos de Ciencia de Datos que est√°n apareciendo en el mundo, seguramente no habr√≠an aparecido si no estuvi√©semos en la "era del Big Data". En el curso no usaremos t√©cnicas de Big Data pero s√≠ hablaremos algo de ellas, principalmente en el tema 4.

Los tiempos est√°n cambiando ([The Times They Are A Changin'](https://www.youtube.com/watch?v=-e7b09L4jY8)) dec√≠a Bob Dylan en el 64. Quiz√°s los tiempos siempre han estado cambiando y siempre cambiar√°n, pero ahora mismo la mayor√≠a de nosotros tenemos la sensaci√≥n de que todo va muy deprisa. En mi opini√≥n lo que est√° detr√°s de este cambio acelerado del mundo en muchos aspectos tiene que ver con la tecnolog√≠a, fundamentalmente con los ordenadores y las redes que transmiten cantidades ingentes de datos, de informaci√≥n. 


Puede que nada ilustre m√°s estos cambios que lo qu√© he hecho yo para continuar este razonamiento: en lugar de buscar un libro he buscado en Google "la era del Big Data". En estos √∫ltimos a√±os he le√≠do bastante sobre el tema, pero para empezar a pensar me he ido a Google y he buscado el t√©rmino. El tercer resultado me ha llevado  a la Wikipedia (otro de los milagros disruptivos que hemos vivido en las dos √∫ltimas d√©cadas). Igual que he hecho yo para informarme/documentarme, todos los d√≠as utilizamos software, aplicaciones para gestionar la agenda, escuchar radio, comprar, comunicarnos etc ... La tecnolog√≠a est√° presente en todos los aspectos de nuestra vida porque llevamos un ordenador, el tel√©fono m√≥vil, en el bolsillo, y con √©l podemos comunicarnos y recibir y transmitir informaci√≥n a trav√©s de la redes. Esto es lo que ha cambiado el mundo y seguir√° cambi√°ndolo y afectar√° a todas las esferas de nuestra vida, espero que para bien (seguro!!). Pero claro, en el curso no vamos a hablar de todo esto, solo de trasfondo, sino que nos centraremos en los datos, en como tratar, manejar y obtener informaci√≥n de las grandes cantidades de datos que consumimos y generamos constantemente; as√≠ que, dejaremos las posibles implicaciones sociales, pol√≠ticas, filos√≥ficas para otros cursos y bajemos a cosas m√°s concretas.


### ¬øQu√© significa, qu√© es Big Data?

Pues es un t√©rmino polis√©mico, tiene distintos significados. Luego ser√© m√°s preciso y riguroso, pero de momento podemos pensar que Big Data significa que tenemos muuuuchos datos, muchos. Esta disponibilidad de datos es uno de los principales factores que explican porqu√© el desarrollo t√©cnico se ha acelerado en los √∫ltimos tiempos. 

Lo que ha pasado es que, el hecho de que los cient√≠ficos dispongan ahora de muchos datos ha dado un fuerte impulso a un campo de la Inteligencia Artificial (concretamente el campo del Machine Learning/Deep Learning) que ha hecho que las m√°quinas, los ordenadores, los robots, puedan hacer cosas que antes eran inimaginables, como por ejemplo que Alexa nos entienda, que haya coches aut√≥nomos que conduzcan mejor que los humanos, que un ordenador gane al campe√≥n mundial de ajedrez (esto paso ya hace mucho tiempo, en 1996, antes de la era del Big data ^[Realmente [Deep Blue](https://es.wikipedia.org/wiki/Deep_Blue_(computadora)), el ordenador que gano a Kasparov, no hacia uso de datos sino que usaba el calculo de probabilidades]). 

En los medios, en la tele, se habla, aparece el t√©rmino "la era del Big data" significando m√°s o menos lo que os he contado, que la "abundancia de datos" est√° impulsando fuertemente el desarrollo tecnol√≥gico, de forma que ahora tenemos acceso a aplicaciones que hasta hace bien poco parec√≠an ciencia ficci√≥n. 

Este acelerado cambio t√©cnico y sus aplicaciones, va a tener y est√° teniendo innumerables efectos en todos los √°mbitos de nuestra vida y tambi√©n en el de las empresas e industrias. Muchas industrias, como la del transporte van a ver como el escenario cambia y, muy posiblemente, las que no sepan entender y aprovechar los nuevos retos tecnol√≥gicos posiblemente acaben despareciendo; evidentemente esto genera, ya sea real o no, una urgencia en las empresas por intentar no quedarse fuera de este cambio acelerado y esto, en principio, genera mayor demanda de profesionales que sepan de tecnolog√≠a y de datos. Bien, creo que ya tenemos un poco m√°s claro que significa esto de "la era del Big Data".

El t√©rmino Big Data es relativamente nuevo, y en castellano se suele traducir como "Datos masivos", aunque ahora mismo en la wikipedia pone "Macrodatos" y [aqu√≠](https://www.fundeu.es/recomendacion/macrodatosalternativa-abig-data-1582/) recomiendan el uso del t√©rmino  Macrodatos. A mi personalmente no me acaba de gustar este t√©rmino, pero quiz√°s sea por el hecho de que tengo formaci√≥n de economista, y el t√©rmino macrodatos me recuerda a los datos macroecon√≥micos. En cualquier caso, el t√©rmino usado habitualmente es el ingl√©s: Big Data.

El t√©rmino tiene matices, y variantes, pero para mi, la caracter√≠stica definitoria de datos Big es el hecho de que estos datos tengan tal volumen (o complejidad) que no "quepan", que no puedan "manejarse" en un ordenador, en realidad que no puedan tratarse con las aplicaciones inform√°ticas habituales. Tal y como figura en la Wikipedia: "es un t√©rmino que hace referencia al concepto relativo a conjuntos de datos tan grandes y complejos como para que hagan falta aplicaciones inform√°ticas no tradicionales de procesamiento de datos para tratarlos adecuadamente"

Luego hay "definiciones" m√°s elaboradas como una famosa, de 2001 en la que se destacaban tres aspectos en el Big Data, **las tres "v's"** del Big Data: **volumen, velocidad y variedad**: despu√©s se han a√±adido 2 uves m√°s y se habla de 5 uves o  5 aspectos relacionados con el Big Data: **v**olumen de datos, **v**elocidad con la que se obtienen y transfieren, **v**ariedad de tipos de datos (texto, im√°genes etc...), **v**eracidad de las fuentes, y un quinto aspecto  a considerar es el **v**alor que aportan los datos. En [este texto](https://www.bbva.com/es/las-cinco-uves-del-big-data/) cortito lo explican bien.

Se pueden mirar m√°s aspectos del Big data, pero lo fundamental es que son datos, que ya sea por su volumen, por su variedad, o por su velocidad no son f√°ciles de almacenar/tratar/manejar con las t√©cnicas y ordenadores habituales. Este hecho da lugar a que el mercado, las empresas, necesiten personas que sean capaces de gestionar la infraestructura de hardware y software para manejar Datos masivos, estas personas generalmente son ingenieros de software, o inform√°ticos. Adem√°s de almacenar y distribuir los datos las empresas tambi√©n necesitan personas que sean capaces de analizar y obtener informaci√≥n y valor de esos datos, el perfil de estas personas es menos uniforme, puede que sean ingenieros, matem√°ticos, estad√≠sticos, economistas (why not?), bi√≥logos, s√≠ en Biolog√≠a con el estudio del genoma y los genes es uno de los campos donde m√°s se est√° haciendo Ciencia de Datos.

En cualquier caso, como es un √°rea o campo de estudio relativamente nueva y adem√°s en constante evoluci√≥n, los t√©rminos y conceptos a√∫n est√°n defini√©ndose y evolucionando; por ejemplo, ya se empieza a hablar del ["smart data"](https://retina.elpais.com/retina/2018/01/12/tendencias/1515763421_780579.html). En este art√≠culo se√±alan que: 

>"El t√©rmino big data ... hace referencia a conjuntos de datos que, debido a su gran volumen, necesitan sistemas especializados de almacenado y procesado para poder trabajar con ellos de manera eficiente .... La informaci√≥n es importante, s√≠, pero demasiada puede llegar a ser confusa y hasta contraproducente .... Aqu√≠ es donde el big data da un paso hacia adelante, el smart data, que se encarga de detectar se√±ales y patrones relevantes a trav√©s de algoritmos inteligentes". 

Esto a m√≠ me suena al objetivo fundamental de la Ciencia de Datos, extraer informaci√≥n a partir de los datos de forma que se genere conocimiento y/o valor.


Muchas veces si le√©is un articulo relacionado con "el Big Data" aparecen palabras extra√±as: Keras, TensorFlow, Apache, ApacheSpark, Mongo, MongoDB, Maria, Cassandra,  .... y much√≠simas m√°s. Yo conozco algunas un poco, otras me suenan y otras me suenan a chino. ¬øQu√© son? Pues en general son nombres de aplicaciones inform√°ticas, o repositorios de datos, o empresas, o paquetes, frameworks,  ..., que se utilizan para almacenar/tratar/manejar/estimar modelos con grandes vol√∫menes de datos. Por ejemplo [Apache](https://es.wikipedia.org/wiki/Apache_Software_Foundation) es una fundaci√≥n de software libre, que se ocupa de hacer proyectos que en la pr√°ctica posibilitan hacer Big data, implementar los nuevas t√©cnicas, con software y plataformas open source. Como la fundaci√≥n Apache tiene muchos proyectos y "productos", por eso hay ApacheSpark, Cassandra, Geronimo etc... 


Esta infraestructura, tanto f√≠sica (ordenadores, repositorios), como de software/programas que se utilizan en Big Data cambian muy deprisa. Constantemente est√°n surgiendo nuevas empresas, nuevos m√©todos, un nuevo algoritmo, una nueva implementaci√≥n de algo ya existente, etc... 


Nos acaba de parecer otra palabra importante en este campo de conocimiento, los algoritmos, ya hablaremos de ellos y su importancia en "la era del Big Data".


Quiero llamaros la atenci√≥n sobre varias ideas que, como much√≠simas otras no trataremos en el curso ^[En realidad con aprender a programar un poco con R para poder ser m√°s eficientes trabajando con datos ya tenemos bastante tarea en el curso], algunas  de ellas provienen de [este art√≠culo](https://www.infobae.com/opinion/2018/08/22/la-ciencia-de-los-datos-y-su-impacto-en-la-economia-la-politica-y-la-sociedad/):

- Los datos hoy son omnipresentes y a menudo abrumadores. Producimos, organizamos y consumimos datos de manera casi constante. Estamos rodeados de informaci√≥n que no para de aumentar. Una de las principales fuentes de datos son nuestras acciones en la red (clicks, likes, rating, shares, etc... ), pero tambi√©n hay muchos datos provenientes de sensores en m√°quinas y procesos, piensa por ejemplo en la informaci√≥n que genera un coche de Formula 1, o un sonda espacial, o el VAR que hay en el f√∫tbol. A modo de ejemplo, [Data Never Sleeps 6.0 de Domo](https://www.domo.com/learn/data-never-sleeps-6) inform√≥ que en 2018 Google realiz√≥ un promedio de 3.8 millones de b√∫squedas por minuto.

- De la misma forma que  Internet cambi√≥ radicalmente el mundo al a√±adir comunicaci√≥n, los datos masivos modificaran aspectos fundamentales de nuestra vida otorg√°ndole una dimensi√≥n cuantitativa que nunca hab√≠a tenido antes

- Ante tal volumen de datos, el desaf√≠o es construir conocimiento usando los datos m√°s relevantes y diversos, no solo para nosotros, sino para nuestra sociedad en su conjunto.


- Hasta hace algunas d√©cadas la recopilaci√≥n de la informaci√≥n estaba mayormente a cargo de los Estados nacionales, pero, ahora mismo, gran parte de los datos est√°n en manos de empresas privadas (Google, Facebook, Amazon, ... ). Esto tiene y puede tener fuertes implicaciones y consecuencias.



-  El poseer datos puede dar poder/beneficio/ventajas competitivas a quien los posea. Por ejemplo, seg√∫n los expertos, el mejor traductor online no es Google Translator sino [DeepL](https://www.deepl.com/es/translator). Los dos servicios utilizan algoritmos de inteligencia artificial, pero parece ser que DeepL tiene mejores datos. DeepL utiliza los datos del proyecto Lingueee que ha permitido construir una base de datos enorme. Lo explican [aqu√≠](https://www.xataka.com/servicios/deepl-vs-google-translate-quien-gana-batalla-traductores-online)

- El ejemplo anterior ilustra que lo que hay detr√°s de los avances no son los algoritmos o la IA/ML/DL, sino los datos: el gran volumen de datos es lo que ha hecho posible esta √©poca de avances tecnol√≥gicos acelerados; en este sentido se suele decir que [los datos son el nuevo petroleo](https://www.europeandataportal.eu/en/highlights/ode-open-data-benefits-open-data-compared-oil), pero a diferencia de este, cuyas reservas podemos considerar fijas, el volumen de datos no hace sino crecer, son m√°s f√°ciles de transportar y generan m√°s valor para la sociedad cuanta m√°s gente los usa.

- Obviamente, la gran disponibilidad de datos tiene tambi√©n aspectos m√°s oscuros o con potenciales peligros, como por ejemplo aspectos legales en la seguridad y [privacidad](https://www.youtube.com/watch?v=pT19VwBAqKA&feature=youtu.be), o sesgos en los datos. Ya no s√≥lo que los gobiernos corten internet o esp√≠en a los ciudadanos, como por ejemplo el caso Snowden o el plan de cr√©dito social chino, sino que est√° emergiendo un [mercado de espionaje digital](https://www.vice.com/en_us/article/ne879z/i-tracked-someone-with-license-plate-readers-drn).


En [este post](https://www.forbes.com/sites/neilmalhotra/2019/07/01/making-sure-ai-is-socially-responsible/#6a96f16c660c) hablan de c√≥mo favorecer que las aplicaciones surgidas de la AI sean socialmente responsables o que los algoritmos no acaben reproduciendo los sesgos presentes en los datos. En [esta gu√≠a para el dise√±o responsable de sistemas de IA](https://www.turing.ac.uk/sites/default/files/2019-06/understanding_artificial_intelligence_ethics_and_safety.pdf) del Alan Turing Institute desarrollan est√°s ideas. 


- Cuando se dispone de datos sensibles, por ejemplo datos m√©dicos, aparece el dilema entre privacidad e informaci√≥n que puede ser beneficiosa para sociedad. Siempre se puede tratar de anonimizar los datos, pero parece ser que a los expertos les resulta no demasiado complicado recuperar la informaci√≥n original; es  decir, a veces es posible la [reidentificaci√≥n](https://www.datanalytics.com/2019/08/27/mas-sobre-la-anonimidad-y-reidentificacion-en-ficheros-de-microdatos/) de ficheros anonimizados. M√°s sobre esto [aqu√≠](https://www.youtube.com/watch?v=pT19VwBAqKA) y [aqu√≠](https://hipertextual.com/2019/09/privacidad-diferencial-datos?utm_medium=feed&utm_source=feedpress.me&utm_campaign=Feed%3A+hipertextual).

- Como en otras facetas de la vida, la informaci√≥n y transparencia es clave a la hora de reducir los posibles riesgos de las aplicaciones de IA. Es importante que el c√≥digo fuente de las aplicaciones y algoritmos sea de acceso libre. Como ejemplo [este art√≠culo](https://www.publico.es/sociedad/transparencia-gobierno-no-quiere-publicar-funcionan-aplicaciones-algoritmos-debera-explicar.html) de P√∫blico o este [paper](https://www.tandfonline.com/doi/full/10.1080/1369118X.2018.1477967).

<br>

## 2. IA, ML y DL

Inteligencia Artificial (IA), Machine Learning (ML) y Deep Learning (DL) ^[Los dos √∫ltimos t√©rminos en castellano ser√≠an: Aprendizaje M√°quina y Aprendizaje Profundo] son tres palabras/conceptos que aparecen constantemente en la era del Big Data. [Aqu√≠](https://blogthinkbig.com/artificial-intelligence-machine-learning-y-deep-learning-conoces-las-diferencias) tienes un post sencillo y claro sobre estos tres t√©rminos.

La primera idea a retener est√° resumida en la infograf√≠a que veis m√°s abajo y que proviene de este [post](https://hackernoon.com/are-you-using-the-term-ai-incorrectly-911ac23ab4f5)




```{r , echo=FALSE, eval = TRUE, fig.asp = 4/2, out.width = "75%", fig.align = "center", fig.cap = 'IA, ML y DL'}
knitr::include_graphics(here::here("imagenes", "tt_01_img_01_AI-ML-DL.png"))
```



Como se aprecia en la infograf√≠a, DL es un subconjunto del ML y ML es un campo de la IA. Vamos que tanto DL como ML son aplicaciones espec√≠ficas de IA. La IA surgi√≥ en los 50 y el ML puede verse como un enfoque de la IA que empez√≥ a coger fuerza en los 80 y que supuso un cambio de paradigma en como se afrontaba la IA.

Primero veamos qu√© es la IA. Para ello voy a recurrir de nuevo a la [Wikipedia](https://es.wikipedia.org/wiki/Inteligencia_artificial) y a lo que ya s√© sobre IA para redactar unos p√°rrafos que os den cierta idea de qu√© es la IA.  

La Wikipedia empieza diciendo: "IA es la inteligencia llevada a cabo por m√°quinas". Esta primera frase no aclara mucho, pero es que  a veces la cosas cuestan. Lo intento yo: IA es un campo de conocimiento, compartido por varias ciencias, cuyo objetivo podemos pensar qu√© es que la maquinas sean inteligentes. Las maquinas no son humanos, nunca van a poder ser inteligentes en un sentido amplio o humano, s√≥lo en la ciencia-ficci√≥n, pero s√≠ pueden tener comportamientos "inteligentes"; es decir que hagan cosas que simulen la inteligencia humana como por ejemplo resolver problemas o dicho de forma m√°s t√©cnica, en funci√≥n de unas variables de entorno tomar una decisi√≥n (esto es lo que hace por ejemplo un ordenador que juega al ajedrez, en funci√≥n de las posiciones de las piezas en el tablero toma una decisi√≥n sobre que pieza mover). Una definici√≥n concisa del campo ser√≠a: el esfuerzo por automatizar las tareas intelectuales normalmente realizadas por los seres humanos.

La idea fundamental en que se basa la Inteligencia Artificial es conseguir que una computadora resuelva un problema complejo como lo har√≠a un humano. Es decir, seg√∫n Andreas Kaplan y Michael Haenlein definen la inteligencia artificial es "la capacidad de un sistema para interpretar correctamente datos externos, para aprender de dichos datos y emplear esos conocimientos para lograr tareas y metas concretas a trav√©s de la adaptaci√≥n flexible". Por ejemplo, conducir un coche.


¬øDesde cuando existe la inteligencia artificial? Pues desde hace bastante ..... no hab√≠ais nacido, ni yo tampoco. 

La inteligencia artificial naci√≥ en la d√©cada de 1950, cuando un pu√±ado de pioneros del campo de la inform√°tica comenz√≥ a preguntarse si las computadoras pod√≠an "pensar", una pregunta cuyas ramificaciones se est√°n explorando todav√≠a hoy. La idea principal que subyace al campo de la IA es conseguir que una computadora resuelva un problema o tarea compleja como lo har√≠a un humano. 


Durante las primeras etapas, mediados de los 60, se pensaba que la IA podr√≠a lograrse elaborando un conjunto suficientemente grande de reglas expl√≠citas para manipular conocimiento o datos. En esta fase, se desarrollaron aplicaciones conocidas como sistemas expertos, en los que se cre√≠a que un potente ordenador y un conjunto de reglas de razonamiento podr√≠an emular el razonamiento humano. Este enfoque se conoce como IA simb√≥lica, y fue el paradigma dominante en IA hasta finales de los 80. 


La IA simb√≥lica demostr√≥ ser adecuada para resolver problemas l√≥gicos bien definidos, como jugar al ajedrez, pero result√≥ dif√≠cil encontrar reglas expl√≠citas para resolver otro tipo de  problemas complejos y difusos, como la clasificaci√≥n de im√°genes, el reconocimiento de voz o la traducci√≥n de textos; de forma que hoy en d√≠a se utiliza otro enfoque: el Machine Learning o Aprendizaje Maquina. 


Como se√±alan [aqu√≠](https://empresas.blogthinkbig.com/atrevete-con-el-deep-learning/), no fue hasta los a√±os 80, casi 30 a√±os despu√©s del los inicios de la IA, que empez√≥ a cobrar importancia el aprendizaje autom√°tico o Machine Learning. Se trata de una forma de IA que ya no necesita un programador que codifique reglas, sino que es capaz de establecer sus propias reglas y aprender por s√≠ misma. 

La idea b√°sica detr√°s del ML consiste en que, en lugar de darle al ordenador un conjunto de reglas para procesar los datos, es el propio ordenador el que aprende esas reglas mirando/analizando los datos. ¬øC√≥mo? Ya lo veremos, pero lo que est√° claro es que el enfoque/paradigma ha cambiado: en lugar de programar y dar al ordenador unas reglas o programa para procesar los datos y devolvernos respuestas/acciones, el enfoque del ML provee a la maquina con los datos y las respuestas esperadas con esos datos y nos devuelve las "reglas". Estas reglas pueden aplicarse a nuevos datos para producir las respuestas en esos nuevos datos. Un sistema que usa ML no es expl√≠citamente programado, sino que se le provee de suficientes datos (relevantes para la tarea que se espera que haga) y encuentra las reglas (o estructura estad√≠stica) en esos datos o ejemplos y, si todo funciona bien, el sistema aprende y encuentra las reglas/patrones para poder automatizar la tarea y que sea llevada a cabo por la m√°quina. Un sistema/programa de ML es entrenado m√°s que expl√≠citamente programado.


Un ejemplo puede ayudar a entenderlo: ¬øC√≥mo se ense√±a a un ni√±o qu√© es un gato y qu√© es un perro? No se le provee de reglas, no se le dice, mira un gato tiene dos orejas puntiagudas, bigotes, cola y cuatro patas; generalmente se le ense√±a al ni√±o con ejemplos, se le ense√±an fotos de gatos y perros y es el propio ni√±o quien aprende las reglas de forma que sin que nadie le diga nada, cuando ve un gato por la calle lo identifica, quiz√°s al principio se equivoca pero conforme se le dan m√°s ejemplos acaba aprendiendo a reconocer/etiquetar a los gatos. Conforme el ni√±o practica, cada vez lo hace mejor; es decir, aprende. Lo que es destacable es que no es necesario ense√±ar ninguna regla al ni√±o; es decir, parece que los humanos tenemos "de serie" mecanismos de clasificaci√≥n, podemos inferir reglas de clasificaci√≥n, reglas que usamos pero que nos es dif√≠cil describir. 


Este es el enfoque que utiliza el ML, no se programan las reglas (o caracter√≠sticas) del problema o cuesti√≥n a analizar (identificar gatos), sino que se le provee de datos (fotos de gatos y de perros) correctamente etiquetadas y mediante t√©cnicas estad√≠sticas/algoritmos √©l s√≥lo encuentra las reglas para diferenciar entre perros y gatos. Una vez el programa/ordenador ha encontrado las reglas, se le  pueden pasar nuevas fotos de perros y gatos (est√° vez sin etiquetar) y √©l las etiquetar√°. En cierta forma el ordenador ha aprendido de los datos y sabe diferenciar gatos de perros. Esta capacidad de generalizar, de aplicar los conocimientos adquiridos a trav√©s de la formaci√≥n a ejemplos y situaciones nuevos, es una caracter√≠stica clave tanto del aprendizaje humano como del aprendizaje autom√°tico. Por supuesto, el aprendizaje humano es mucho m√°s sofisticado que los algoritmos m√°s avanzados de aprendizaje autom√°tico, pero las computadoras tienen la ventaja de tener mayor capacidad para el procesado de datos. 

Los cient√≠ficos que trabajan el campo del ML/DL utilizan t√©cnicas de ML para elaborar aplicaciones o programas que funcionen para resolver/hacer una tarea concreta, como por ejemplo detectar spam, sugerir una ruta de tr√°fico, clasificar una imagen, traducir un texto, reconocer el lenguaje hablado, etc... [Aqu√≠](https://www.youtube.com/watch?v=kopoLzvh5jY) puedes ver a dos inteligencias artificiales aprendiendo a jugar al escondite.Despu√©s de unas cuantos millones de partidas han aprendido bastante bien, incluso a colaborar para esconderse mejor En [este art√≠culo](https://www.technologyreview.com/s/614325/open-ai-algorithms-learned-tool-use-and-cooperation-after-hide-and-seek-games/) lo explican un poco.

En el campo del ML/DL se utilizan t√©cnicas estad√≠sticas/algoritmos de aprendizaje. Hay muchos tipos de ellos. La elecci√≥n del m√°s adecuado, depender√° del tipo de tarea que se quiera resolver en cada caso. Por ejemplo, podemos hablar de algoritmos de clasificaci√≥n como los √°rboles de decisi√≥n, o Na√Øve Bayes, algoritmos de regresi√≥n, de clustering, de an√°lisis de componentes principales, redes neuronales, ...

Con ML no nos encontraremos con ordenadores que piensan en el sentido humano, solamente estaremos utilizando el poder de computo de los ordenadores para obtener informaci√≥n a partir de un conjunto de datos; en realidad estamos usando ML para dar sentido a los datos. Las t√©cnicas de ML se pueden aplicar a muchos campos, desde la pol√≠tica hasta las neurociencias. Es una herramienta que se puede aplicar a muchos problemas. Cualquier campo que necesite interpretar y actuar sobre los datos puede beneficiarse de las t√©cnicas de aprendizaje autom√°tico. De hecho, estas t√©cnicas, principalmente las de aprendizaje profundo, se est√°n convirtiendo en el motor que impulsa la econom√≠a moderna basada en datos y para que ese motor funcione se necesita "energ√≠a", y la energ√≠a la proporcionan los datos. En ese sentido se dice que los datos son el nuevo petroleo. Lo importante no son tanto las t√©cnicas, sino los datos que alimentan a los algoritmos.

Para acabar esta secci√≥n os dejo algunos p√°rrafos/ideas que me han llamado la atenci√≥n^[No recuerdo exactamente la fuente] y que creo que pueden seros de utilidad:


- La sociedad ha de desprenderse de la obsesi√≥n por la causalidad a cambio de meras correlaciones. Ya no sabremos por qu√© sino s√≥lo qu√©. Da al traste con las pr√°cticas establecidas hace siglos y choca con nuestra comprensi√≥n m√°s elemental sobre como tomar decisiones y aprehender la realidad.

- Los datos masivos tratan del qu√©, no del porqu√©. No siempre necesitamos saber la causa. Antes el an√°lisis se limitaba a mirar un limitado numero de hip√≥tesis que se defin√≠an con precisi√≥n incluso antes de recopilar los datos


- Esencialmente los datos masivos sirven para hacer predicciones. Aunque se les engloba en la ciencia de la computaci√≥n llamada IA y m√°s espec√≠ficamente en Aprendizaje autom√°tico o Machine Learning. 


- La palabra learning o aprendizaje induce a error porque no se le ense√±a a pensar como un ser humano; m√°s bien consiste en aplicar algoritmos a datos masivos para inferir probabilidades  



Respecto al Deep Learning, simplemente volver a decir que un subconjunto del ML. Son t√©cnicas m√°s complejas en t√©rminos computacionales y por lo tanto necesitan para aprender un mayor volumen de datos, pero su filosof√≠a es la misma. Proveer de datos para que el ordenador aprenda a resolver y automatizar una tarea concreta. Utilizan algoritmos m√°s complejos o con m√°s elementos o capas. Pr√°cticamente todas las aplicaciones exitosas utilizan t√©cnicas de DL, y generalmente algoritmos basados en redes neuronales.

Os dejo algunas ideas frases sobre DL provenientes de [este fant√°stico art√≠culo](https://empresas.blogthinkbig.com/atrevete-con-el-deep-learning/):

- El Deep Learning es una de las √°reas de investigaci√≥n m√°s populares dentro del campo de la Inteligencia Artificial en los √∫ltimos a√±os porque, gracias a estas t√©cnicas, cosas como la visi√≥n artificial o el procesamiento del lenguaje natural han saltado del √°mbito de la ciencia ficci√≥n a la realidad.

- El Deep Learning es tan importante porque est√° permitiendo resolver de forma m√°s f√°cil y eficiente un gran n√∫mero de problemas. Por una parte, realiza de forma autom√°tica una de las tareas m√°s complejas del proceso de trabajo de Machine Learning: la ingenier√≠a de atributos^[en ML/DL cuando hablan de atributos se refieren, m√°s o menos, al termino regresores en Econometr√≠a]. Las redes neuronales seleccionan de forma autom√°tica qu√© atributos son los relevantes y cu√°les se pueden desechar. 

- Otra de las grandes ventajas de trabajar con redes neuronales es que permiten trabajar con cualquier tipo de input. Cualquiera: n√∫meros, im√°genes, sonidos, textos, series temporales. Teniendo en cuenta que los datos no estructurados, aquellos que no encajan en la estructura tradicional filas/columnas de las bases de datos relacionales, suponen m√°s de un 90% de todos los datos generados, es f√°cil comprender la importancia de poder manejarlos de forma eficiente. Estamos hablando de datos como mensajes de correo, v√≠deos, ficheros de audio, p√°ginas web, mensajes en redes sociales etc.

- Una red neuronal entrenada con datos etiquetados, tambi√©n se puede aplicar a datos no estructurados, lo cual les da a los algoritmos de Deep Learning una gran ventaja respecto a otros algoritmos al poner a su disposici√≥n un volumen de datos de entrenamiento mucho mayor. Algoritmos no muy buenos entrenados con enormes conjuntos de datos pueden dar mejores resultados que buenos algoritmos entrenemos con conjuntos de datos reducidos. De hecho, mientras en el caso de los algoritmos tradicionales usados en Machine Learning llega un momento en el un mayor volumen de datos no implica un mejor rendimiento, en el caso del Deep Learning no ocurre as√≠. El rendimiento no deja de crecer, seg√∫n lo hacen el volumen de datos y el n√∫mero de capas del modelo.


Como ya sab√©is, aunque el curso tiene un tema sobre ML, el tercero, en el que se har√° una introducci√≥n a la terminolog√≠a y principales m√©todos del ML, en realidad el curso no est√° orientado al ML, ni mucho menos al DL, sino que est√° m√°s orientado a ser una introducci√≥n a la ciencia de datos (DS).

¬øQue qu√© es la Ciencia de datos? Pues voy a tratar de explicarlo en el siguiente apartado.



## 3. Ciencia de Datos

Como se dijo en el prefacio, DS es una nueva disciplina^[Aunque el t√©rmino Ciencia de datos se remonta, seg√∫n la Wikipedia al menos a principios de los 70] que se incorpora poco a poco, pero con mucha fuerza, a la mayor√≠a de planes de estudio, incluida la Econom√≠a. Por ejemplo, [este M√°ster de la LSE](http://www.lse.ac.uk/study-at-lse/Graduate/Degree-programmes-2019/MSc-Data-Science). 



¬øDe qu√© se ocupa la ciencia de datos? Pues puede tener varias respuestas, pero en definitiva el objetivo √∫ltimo de la ciencia de datos es transformar los datos en informaci√≥n con sentido. Algunos dir√°n, pero s√≠ ese es el objetivo de la Estad√≠stica. S√≠, es cierto, transformar datos en informaci√≥n es, y ha sido siempre, el objetivo √∫ltimo de la estad√≠stica, PERO lo que habitualmente conocemos por Estad√≠stica se fue conformando con el paso de los a√±os en un contexto en el que conseguir datos era dif√≠cil, as√≠ que se desarrollaron m√©todos y t√©cnicas apropiadas para extraer el m√°ximo de informaci√≥n con muestras de reducido tama√±o. El contexto ha cambiado, vivimos rodeados de datos, de mayor volumen y variedad, lo que provoca nuevos retos a los analistas, y tenemos mayor capacidad de computo, por lo que a veces ya no hay que utilizar aproximaciones asint√≥ticas^[una versi√≥n m√°s amplia y fundamentada de estas ideas puede encontrarse [aqu√≠](https://beanumber.github.io/mdsr2e/ch-prologue.html)]. La American Statistical Asociation (ASA) destaca la importancia de la Estad√≠stica en DS, pero reconoce en [este statement](https://magazine.amstat.org/blog/2015/10/01/asa-statement-on-the-role-of-statistics-in-data-science/) la diferencia entre DS y estad√≠stica.



No es estrictamente cierto, pero podemos pensar que la estad√≠stica tradicional se concentra principalmente en las t√©cnicas, adem√°s dado el contexto de escasez de datos, en un tipo determinado de t√©cnicas; sin embargo la √≥ptica de la ciencia de datos es m√°s amplia. Obviamente se usan y necesitan t√©cnicas estad√≠sticas, pero el enfoque es m√°s global: se hace √©nfasis en que el proceso de an√°lisis de datos comienza desde que se recopilan los datos hasta que se presentan los resultados. El siguiente diagrama ilustra este proceso:



```{r, echo = FALSE, out.width = "90%"}
knitr::include_graphics(here::here("imagenes", "tt_01_img_02_DS-workflow.png"), dpi = 150) 
```



En la Ciencia de datos, etapas como el procesado y limpieza de datos o el an√°lisis gr√°fico, que ocupaban un lugar secundario cuando no marginal en los libros tradicionales de estad√≠stica se han convertido en partes fundamentales del trabajo de un cient√≠fico de datos. 


No solo se considera el an√°lisis de datos como un proceso m√°s global compuesto de varias etapas, sino que dada la complejidad, volumen y variedad de los datos actuales se necesita un fuerte componente tecnol√≥gico generalmente apoyado en los ordenadores y la programaci√≥n. No se puede, o es extremadamente complicado, hacer ciencia de datos sin un ordenador y sin saber programar. Adem√°s en la ciencia de datos se da una gran importancia al contexto en el que se hace Data Science, en cierta forma se reconoce que hace falta saber Econom√≠a para hacer ciencia de datos en el campo de la econom√≠a.

La siguiente infograf√≠a puede ilustrar esta idea, mostrando que, idealmente, para hacer DS se requieren, al menos, tres tipos de competencias o conocimientos: 1) matem√°ticas y estad√≠stica, 2) tecnolog√≠a y programaci√≥n y 3) conocimientos del campo de aplicaci√≥n. En [este post](http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram) explican el diagrama en detalle. Por ejemplo la "Danger Zone".


```{r, echo = FALSE, out.width = "40%"}
knitr::include_graphics(here::here("imagenes", "tt_01_img_03_DS.png")) 
```

En [este post](https://iamnagdev.wordpress.com/2020/02/27/data-science-in-manufacturing-an-overview/) desarrollan estas ideas en el contexto concreto de la industria manufacturera y hacen un listado de potenciales usos de la DS en el campo de las manufacturas.

<br>

En [este post](http://varianceexplained.org/r/ds-ml-ai/) puedes encontrar una visi√≥n de la DS un poco distinta, ya que incide en la diferencias entre DS, ML e IA. Como resumen del post:  "Data science produces insights, Machine learning produces predictions, Artificial intelligence produces actions" 


Dos definiciones sencillas de DS:


- `@YBuhl`: This phrase by `@juliesquid` is worth retweeting it all over again: 
"Data Science is not just about #AI or machine learning. It is the discipline of turning raw data into understanding." 

- `@TiffanyTimbers`: Thinking a lot about the definition of #DataScience. The best that I have read so far comes from `@rafalab`: "the processes used to extract value from data". I think we should extend this and say "the reproducible & transparent processes used to extract value from data"



Por √∫ltimo, 3 "definiciones" de DS medio en broma:

- Un cient√≠fico de datos es un estad√≠stico con pajarita

- Un estad√≠stico que trabaja en San Francisco

- Cient√≠fico de datos (n): Persona que sabe m√°s de estad√≠stica que cualquier programador y que a la vez sabe m√°s de programaci√≥n que cualquier estad√≠stico


<br>

#### ¬øEs f√°cil ser cient√≠fico de datos? 

Pues, como todo, depende, pero si que hay que tener en cuenta que es un campo en contin√∫a evoluci√≥n. Estos post, [1](https://towardsdatascience.com/how-it-feels-to-learn-data-science-in-2019-6ee688498029), [2](https://muestrear-no-es-pecado.netlify.com/2019/02/18/la-modernidad/) y [3](https://github.com/oliviergimenez/Things-a-scientist-is-suppposed-to-know), inciden en lo estresante que puede ser la vida de un cient√≠fico de datos que intente estar al d√≠a de las continuos cambios y evoluciones en este campo.




Parecido a lo que sugiere este tweet:

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Why Data Science is Hard‚Ñ¢<br><br>(slide via <a href="https://twitter.com/bradurani?ref_src=twsrc%5Etfw">@bradurani</a> at <a href="https://twitter.com/hashtag/LeadDevAustin?src=hash&amp;ref_src=twsrc%5Etfw">#LeadDevAustin</a>) <a href="https://t.co/8QcPlRMazw">pic.twitter.com/8QcPlRMazw</a></p>&mdash; Caitlin Hudonüë©üèº
üíª (@beeonaposy) <a href="https://twitter.com/beeonaposy/status/1070787394289446912?ref_src=twsrc%5Etfw">December 6, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 


<br>

Aunque tambi√©n est√° bien desmitificar un poco y tomarse las cosas menos en serio:



<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Love data science <a href="https://t.co/RZ18jaOJRQ">pic.twitter.com/RZ18jaOJRQ</a></p>&mdash; Tim Hopper (@tdhopper) <a href="https://twitter.com/tdhopper/status/730425632862044161?ref_src=twsrc%5Etfw">May 11, 2016</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 


<br>

Como sugiere este otro tweet, no se puede saber todo, ni pasar por la vida sin cometer errores:


<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Vulnerable but important tweets for data scientists &amp; programmers:<br><br>ü§∑IDK: I don&#39;t know<br>üß†TIL: today I learned<br>üò¨ Mistakes I&#39;ve made<br><br>Normalizing the fact that no one knows it all (not even you!), everyone makes mistakes, and learning is a lifelong process has profound impacts.</p>&mdash; Jesse Mostipak (@kierisi) <a href="https://twitter.com/kierisi/status/1068496229439598592?ref_src=twsrc%5Etfw">November 30, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 


<br>

Para finalizar, un hilo de Tweeter con muuuuuuchos errores:


<blockquote class="twitter-tweet"><p lang="en" dir="ltr">A small sample of data science mistakes I&#39;ve made so far üëá <a href="https://t.co/EeiVmmAnuJ">pic.twitter.com/EeiVmmAnuJ</a></p>&mdash; Caitlin Hudonüë©üèº
üíª (@beeonaposy) <a href="https://twitter.com/beeonaposy/status/1122964504910938121?ref_src=twsrc%5Etfw">April 29, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

<br>


## 4. Ciencia de datos en Econom√≠a

Evidentemente todo este cambio tecnol√≥gico acelerado al que asistimos en la era del Big Data, y que muchas veces est√° asociado al ML/DL, ha provocado y provocar√° grandes cambios tanto en la econom√≠a real como en la ciencia econ√≥mica. Una panor√°mica de trabajos que analizan las implicaciones de estos cambios en la ciencia econ√≥mica puede verse en [An√°lisis econ√≥mico de la revoluci√≥n digital](https://blog.funcas.es/wp-content/uploads/2018/11/Economic-Analysis-of-the-Digital-Revolution.pdf).


Uno de los efectos m√°s evidentes consiste en que las innovaciones tecnol√≥gicas asociadas al ML seguramente cambiar√°n radicalmente, si es que no lo han hecho ya, muchos sectores econ√≥micos; por ejemplo el transporte o la banca, pero tambi√©n muchos otros como los seguros, servicios audiovisuales, la venta al por menor, la sanidad, etc...

Otro de los cambios m√°s evidentes consiste en que actualmente las principales corporaciones transnacionales, que antes pertenec√≠an principalmente a los sectores energ√©tico y financiero, ahora tienen un fuerte componente tecnol√≥gico, las **GAFA**, un acr√≥nimo para hacer referencia a las cuatro grandes compa√±√≠as tecnol√≥gicas: Google, Amazon, Facebook y Apple.

Otra de los cambios significativos que han sido propiciados por las nuevas tecnolog√≠as es la llamada **econom√≠a colaborativa** al que est√°n asociadas empresas como BlaBlaCar, Airbnb, ...

Otro cambio evidente consiste en que ahora mismo hay una econom√≠a de los datos. Los datos se han convertido en materia prima, capaz de crear valor, fuente de innovaci√≥n y servicios nuevos. Para una panor√°mica de est√° econom√≠a de los datos puede verse la publicaci√≥n [Econom√≠a de los Datos. Riqueza 4.0](https://www.fundacioncarolina.es/wp-content/uploads/2018/11/Libro-Economia-de-los-Datos-Ontiveros.pdf).


Se habla incluso de que estamos inmersos en una **cuarta revoluci√≥n industrial**. El concepto de cuarta revoluci√≥n industrial fue acu√±ado por Klaus Schwab fundador del Foro Econ√≥mico Mundial en el contexto de la edici√≥n del Foro Econ√≥mico Mundial 2016 y una de sus caracter√≠sticas es la utilizaci√≥n de la IA/ML/DL para la automatizaci√≥n de tareas que antes s√≥lo estaban al alcance de los humanos. Una de las consecuencias m√°s directas de la automatizaci√≥n ser√° el **desplazamiento de empleos**, no s√≥lo manuales, por las maquinas/algoritmos.


Desde el punto de vista de la ciencia, la actual abundancia de datos, va a tener implicaciones directas:

- "De la misma forma que el telescopio y el microscopio permitieron ver el espacio y las c√©lulas, las nuevas t√©cnicas de recopilaci√≥n y an√°lisis de datos ayudar√°n a ver el sentido de nuestro mundo de una forma que apenas intuimos". 

- "el cambio cuantitativo no es lo √∫nico importante, es el cualitativo: una pel√≠cula es diferente de una pintura, tambi√©n cuando trabajas con muchos datos se pueden hacer otras cosas; es decir,al cambiar la cantidad cambiamos la esencia".

Ha surgido, incluso, una nuevo t√©rmino: el [data√≠smo](https://es.wikipedia.org/wiki/Data%C3%ADsmo). Para un ‚Äúdataista‚Äù, en un mundo con cada vez mayor complejidad, confiar en los datos puede reducir los sesgos cognitivos y descubrir patrones de comportamiento. Seg√∫n el fil√≥sofo y ensayista surcoreano Byung-Chul Han, ‚Äúel big data‚Äù debe liberar el conocimiento de la subjetividad. El t√©rmino dataismo fue popularizado en el libro Homo Deus de Harari. El "dataismo" est√° en cierto modo relacionado con la idea, quiz√° un poco exagerada, de que est√° surgiendo un cuarto paradigma cient√≠fico basado en el uso intensivo de datos. Est√° idea se atribuye a Jim Gray, ganador del premio Turing. Gray afirma que "todo lo relacionado con la ciencia est√° cambiando debido al impacto de la tecnolog√≠a de la informaci√≥n y el diluvio de datos" y que se est√° conformando un cuarto paradigma cient√≠fico tras los tres primeros (emp√≠rico, te√≥rico, computacional). Esta ideas se desarrollan en [The Fourth Paradigm: Data-intensive Scientific Discovery](https://books.google.es/books?id=oGs_AQAAIAAJ&redir_esc=y). Una traducci√≥n al castellano puede encontrarse [aqu√≠](http://www.uam.mx/casadelibrosabiertos/libroselectronicos/4toparadigma/4toparadigma.pdf).



<br>


#### ¬øAfectar√° todo esto a la Econom√≠a/Econometr√≠a?

Todos vosotros sab√©is que la Econom√≠a es una de las ciencias sociales en la que m√°s se utiliza la Estad√≠stica; de hecho la Econometr√≠a es precisamente eso, una rama de la Econom√≠a que utiliza m√©todos estad√≠sticos en el estudio de los fen√≥menos econ√≥micos.

La respuesta a la pregunta anterior es que s√≠, no s√© cuando ni como, pero es evidente que la disponibilidad de nuevos datos, y el auge de los m√©todos estad√≠sticos asociados al ML/DL, tendr√°n que ir incorpor√°ndose poco a poco a nuestra ciencia. Abajo algunas referencias sobre ello:

- [The Economics of Artificial Intelligence: An Agenda](https://www.nber.org/books/agra-1)

- [IA y econom√≠a](http://www.funcas.es/publicaciones_new/Sumario.aspx?IdRef=1-01157)

- [Big Data in economics](https://wol.iza.org/articles/big-data-in-economics/long)

- [Machine Learning: An Applied Econometric Approach](https://www.aeaweb.org/articles?id=10.1257/jep.31.2.87)

- [The Impact of Machine Learning on Economics](https://www.nber.org/chapters/c14009.pdf)

- [Big Data: New Tricks for Econometrics](https://www.aeaweb.org/articles?id=10.1257/jep.28.2.3)


-----------------------------

<br>


## 5. Investigaci√≥n reproducible y software libre

Cada vez m√°s  se oye hablar de la Investigaci√≥n Reproducible (IR) o  Reproducible Research (RR) en ingl√©s. Creo y espero que en poco tiempo se convierta en el est√°ndar. 

Seg√∫n la Wikipedia espa√±ola,  

> La reproducibilidad es la capacidad de una prueba o experimento de ser reproducido o replicado por otros, en particular, por la comunidad cient√≠fica. La reproducibilidad es uno de los pilares del m√©todo cient√≠fico, siendo la falsabilidad el otro. ... 

> ... en muchas disciplinas, sobre todo en aquellas que implican el uso de estad√≠stica y procesos computacionales, se entiende que un estudio es reproducible si es posible recrear exactamente todos los resultados a partir de los datos originales y el **c√≥digo inform√°tico** empleado para los an√°lisis.


En este [libro](https://www.practicereproducibleresearch.org/) se√±alan que la reproducibildad est√° ligada √≠ntimamente al m√©todo cient√≠fico como ilustra el hecho de que el lema de la [Royal Society](https://es.wikipedia.org/wiki/Royal_Society) una de las sociedades cient√≠ficas m√°s antiguas del mundo es *"Nullius in verba"* que quiere decir m√°s o menos "no creas en la palabra de nadie". En el contexto cient√≠fico quiere decir que las afirmaciones o descubrimientos cient√≠ficos deben ser probados mediante el m√©todo cient√≠fico.


A menudo se habla de la existencia de una [crisis de reproducibilidad](https://es.wikipedia.org/wiki/Crisis_de_replicaci%C3%B3n) refiri√©ndose con ello a la idea de que los resultados de muchos de los experimentos cient√≠ficos son dif√≠ciles o imposibles a replicar en investigaciones posteriores. Uno de los casos m√°s sonados, asociados a esta idea, es el de [Reinhart y Rogoff](https://www.weforum.org/agenda/2013/04/the-reinhart-and-rogoff-debacle/).


La idea de que puede existir una crisis de reproducibilidad, junto al hecho de que las nuevas tecnolog√≠as hacen cada vez m√°s sencillo que los art√≠culos e investigaciones cient√≠ficas sean reproducibles, ha provocado cambios importantes en la pol√≠tica de asociaciones y revistas cient√≠ficas, como la de la [American Economic Association](https://www.aeaweb.org/journals/policies/data-code/) seg√∫n la cual, s√≥lo se publicar√°n art√≠culos en los que: 

> "the data and code used in the analysis are clearly and precisely documented, and access to the data and code is clearly and precisely documented and is non-exclusive to the authors".

<br>

Para que un an√°lisis con datos sea reproducible, no s√≥lo es necesario que los datos utilizados han de ser accesibles, sino que c√≥mo m√≠nimo deber√≠a:   

- proporcionar los datos originales (obviamente documentar las fuentes) 
    
- efectuar todo el proceso a trav√©s de c√≥digo (scripts)  
    
- documentar el proceso de trabajo (por ejemplo el orden en que se ejecutaron los scripts)   


<br>

Como veis, uno de los requisitos para hacer investigaci√≥n reproducible es efectuar todo el proceso mediante scripts; es decir, hay que saber programar. Mira lo que dice Frank Harrell:



> Can one be a good data analyst without being a half-good programmer? The short answer to that is, ‚ÄòNo.‚Äô The long answer to that is, ‚ÄòNo.‚Äô    ‚ÄîFrank Harrell   https://homerhanumat.github.io/r-notes/frames.html



<br>


Hacer una investigaci√≥n completamente reproducible es COSTOSO; de hecho, hay cursos completos sobre el tema, por ejemplo [√©ste](http://kbroman.org/Tools4RR/), y muchos proyectos que tratan de promoverla; por ejemplo [√©ste](https://ropensci.org/) que pretende favorecer el uso de datos abiertos a trav√©s de R. Afortunadamente, cada vez hay m√°s herramientas que facilitan hacer IR: Make, Git, Docker, Pandoc, Knitr, markdown ...



Hacer una investigaci√≥n (completamente) reproducible no siempre es posible; OK, PERO al menos acercarse ... un poco. Nosotros en el curso haremos an√°lisis con datos e intentaremos que estos sean reproducibles. En el entorno **R** cada vez es m√°s f√°cil acercarse al ideal de la IR. Para ello en el curso haremos siempre nuestros an√°lisis con scripts de R. Concretamente utilizaremos **RStudio** para hacer an√°lisis de datos, gestionando nuestros an√°lisis a trav√©s de **Rprojects** y generaremos los informes y resultados del an√°lisis con documentos **Rmarkdown**^[En seguida explicaremos que son todas estas palabras que empiezan por r: R, RStudio, Rproject y Rmarkdown]. Estos documentos Rmarkdown o **`.Rmd`** son reproducibles. En breve veremos que significa esto y sus utilidades tanto para la investigaci√≥n como para la docencia. En [estas transparencias](https://mrslaviniag.github.io/xaringan_presentations/rladies_presentation_22_May_2019.html) nos cuentan como R y su ecosistema facilitan el hacer investigaci√≥n o an√°lisis reproducibles. 


La raz√≥n para hacer los an√°lisis reproducibles no s√≥lo es cumplir con los est√°ndares cient√≠ficos, que tambi√©n, sino tambi√©n hay un inter√©s personal para el analista. Para entenderlo puedes ver el siguiente [video de 1'44''](https://www.youtube.com/watch?v=s3JldKoA0zw&feature=youtu.be) que muestra una de las principales ventajas de la IR, y sino ya lo experimentareis cuando hagamos hecho el primer an√°lisis y os diga que me he equivocado con los datos, que os hab√≠a dado la versi√≥n antigua de los datos. Os vais a re√≠r si no hab√©is hecho vuestro an√°lisis reproducible.


En palabras de `@TiffanyTimbers`: 

> Nothing like doing something manually 60+ times and making mistakes to reinforce the idea "automate all the things". 


<br>

### Software libre


El software libre es de vital importancia en el desarrollo de la investigaci√≥n reproducible. Piensa que por mucho que un investigador haga accesible sus datos y su c√≥digo, si utiliza un software privativo, en realidad su an√°lisis no es reproducible, s√≥lo lo ser√° para aquellos que puedan pagar la licencia.

De hecho, actualmente, al menos en el campo de la ciencia de datos, el software libre, o es ya mayoritario, o va camino de serlo. Es verdad que muchas empresas a√∫n basan sus an√°lisis de datos en programas como Excel, SPSS, Stata o SAS, pero la tendencia est√° cambiando y es de esperar que se acelere en un futuro pr√≥ximo. Como ejemplo de esta idea puedes ver est√° publicaci√≥n: [Big Data y open source](https://hipertextual.com/presentado-por/bbva/big-data-y-open-source).


Para aquellos que creen que el software comercial da m√°s garant√≠as, pueden leerse [este post](https://notstatschat.rbind.io/2019/02/18/absolutely-no-warranty/).


Seguramente entre las empresas peque√±as y medianas Excel contin√∫a siendo el software de referencia para sus an√°lisis cuantitativos. S√≠, Excel es un fant√°stico software, lo s√©, pero no sirve para todo. Un ejemplo de esto [aqu√≠](https://www.sciencemag.org/news/2016/08/one-five-genetics-papers-contains-errors-thanks-microsoft-excel), o [aqu√≠](https://www.johndcook.com/blog/2019/09/07/excel-r-bom/). [Este post](https://appsilon.com/excel-is-obsolete-here-are-the-top-2-alternatives-from-r-and-python/?utm_campaign=News&utm_medium=Community&utm_source=DataCamp.com) explica porque **Excel est√° obsoleto**. En los comentarios al post le atizan un poco. En un tono m√°s positivo, [este post](https://outsiderdata.netlify.com/post/why-i-migrated-from-excel-to-r/) explica porque abandonar Excel y migrar a R.


En palabras de Hadley en [esta entrevista](https://www.r-bloggers.com/advice-to-young-and-old-programmers-a-conversation-with-hadley-wickham/amp/)

> I think the tradeoff between Stata and R is: do you want a point-and-click interface, or do you want a programming interface? Point-and-click interfaces are great, because they lay out all of your options in front of you, and you don‚Äôt have to remember anything. You can navigate through the set of pre-supplied options. And that‚Äôs also it‚Äôs greatest weakness, because first of all, you are constrained into what the developer thought you should be able to do. And secondly, because your primary interaction is with a mouse, it‚Äôs very difficult to record what you did. And I think that‚Äôs a problem for science, because ideally you want to say how you actually got these results. And then simply do that reliably and have other people critique you on that. But it‚Äôs also really hard when you are learning, because when you have a problem, how do you communicate that problem to someone else? You basically have to say, ‚ÄúI clicked here, then I clicked here, then I clicked here, and I did this.‚Äù Or you make a screen cast, and it‚Äôs just clunky)


Este tweet incide tambi√©n en alguno de los problemas de Excel. Tienes que ver la respuesta un poquito ir√≥nica de Dale Maschette, muy buena!! Para ello pincha en el tweet:



```{r, echo = FALSE, fig.asp = 7/9}
tweetrmd::tweet_embed("https://twitter.com/Dale_Masch/status/1138564316594970624", theme = "light", align = "center", dnt = TRUE, plain = TRUE, maxwidth = 400)
```

<br>

Aqu√≠ tenemos un problema concreto que ha generado Excel al ser usado en al an√°lisis de datos: han tenido que renombrar los genes para evitar que Excel interprete sus nombres como fechas.


```{r, echo = FALSE, fig.asp = 7/9}
tweetrmd::tweet_embed("https://twitter.com/_ColinFay/status/1294208622080204800", theme = "light", align = "center", dnt = TRUE, plain = TRUE, maxwidth = 400)
```


<br>
  

Yo no digo nada, pero ...


```{r, echo = FALSE, eval = TRUE, fig.asp = 4/2, out.width = "75%", fig.align = "center"}
knitr::include_graphics(here::here("./imagenes/R_como_cars.jpeg"))
```

<br>

Please, **don't look** [this other one](http://crashworks.org/if_programming_languages_were_vehicles/)  `r emo::ji("smile")` !!!



<br>

-------------------------


## 6. ¬øPor qu√© R?

En el curso usaremos R y RStudio. En la actualidad, en el campo de la ciencia de datos, hay s√≥lo 2 alternativas, Phyton o R. De hecho hay un intenso debate sobre cual es m√°s adecuado. Hay muchas opiniones al respecto, pero yo he seleccionado [esta](https://mchow.com/posts/data-science-cbk/) y [esta](https://blog.shotwell.ca/posts/why_i_use_r/), aunque la verdad, tampoco es necesario elegir un s√≥lo lenguaje, [R y Phyton pueden colaborar](https://blog.rstudio.com/2019/12/17/r-vs-python-what-s-the-best-for-language-for-data-science/).

Evidentemente mi opini√≥n es que para ciencia de datos R est√° varios pasos por delante de Phyton; si bien es verdad, que para hacer ML, y principalmente DL, Phyton puede ser m√°s adecuado. En palabras de Hadley en [esta entrevista](https://www.r-bloggers.com/advice-to-young-and-old-programmers-a-conversation-with-hadley-wickham/amp/)


> For R and Python, Python is first and foremost a programming language. And that has a lot of good features, but it tends to mean, that if you are going to do data science in Python, you have to first learn how to program in Python. Whereas I think you are going to get up and running faster with R, than with Python because there‚Äôs just a bunch more stuff built in and you don‚Äôt have to learn as many programming concepts. You can focus on being a great political scientist or whatever you do and learning enough R that you don‚Äôt have to become an expert programmer as well to get stuff done.


Este tweet^[Algunas de las respuestas al tweet son muy buenas] ejemplifica un poco la rivalidad (con buen rollo) entre R y Phyton:

```{r, echo = FALSE, fig.asp = 7/9}
tweetrmd::tweet_embed("https://twitter.com/dinga92/status/1273685480958242823", theme = "light", align = "center", dnt = TRUE, plain = TRUE, maxwidth = 400)
```


Aunque despu√©s de lo que dijo Elmo, yo creo que el debate est√° zanjado:

```{r, echo = FALSE, fig.asp = 7/9}
library(tweetrmd)   #- devtools::install_github("gadenbuie/tweetrmd")
tweetrmd::tweet_embed("https://twitter.com/minebocek/status/1174382623499661312", theme = "dark", align = "center", dnt = TRUE, plain = TRUE, maxwidth = 300)
```



R se est√° convirtiendo en el software estad√≠stico de referencia en la mayor√≠a de los centros de investigaci√≥n y universidades, y su uso se est√° extendiendo tambi√©n dentro de la empresa privada. R es software libre, gratuito y est√° incorporando m√°s r√°pidamente que otros programas las t√©cnicas avanzadas de an√°lisis de datos que se est√°n desarrollando en los √∫ltimos a√±os. Otro aspecto importante que convierte a R en una herramienta muy potente es que incorpora un lenguaje de programaci√≥n sencillo y muy flexible, que permite tener un control total sobre el an√°lisis que se est√° desarrollando


Creo que en la actualidad R es el mejor programa para iniciarse y hacer an√°lisis de datos. Si no me acabas de creer, o quieres leer algo sobre la importancia y capacidades de R puedes hacerlo [aqu√≠](http://nadaesgratis.es/fernandez-villaverde/r) o [aqu√≠](https://www.r-bloggers.com/why-r-is-the-best-data-science-language-to-learn-today/), o [aqu√≠](https://shirinsplayground.netlify.com/2017/09/ode_to_r/) o m√°s recientemente [aqu√≠](https://www.eoda.de/en/wissen/blog/r-python-julia-data-science-2019).

<br>

R es cada vez m√°s usado, no s√≥lo en la universidad y la docencia, sino tambi√©n en el mundo de la empresa, puedes verlo [aqu√≠](https://www.r-bloggers.com/six-reasons-to-learn-r-for-business/) o [aqu√≠](http://blog.sellorm.com/2016/11/26/talk-r-is-production-safe/). Una de las conferencias m√°s importantes sobre el uso comercial de R es [The Enterprise Applications of the R Language Conference (EARL)](https://earlconf.com/#info).

Entre las empresas que usan R est√°n: Google, Facebook, Twitter, Microsoft, IBM, Uber, Ford, Airbnb, American Express,  Barclays Bank, [Bank of America](https://www.r-bloggers.com/bank-of-america-uses-r-for-reporting/)... [Aqu√≠](https://www.listendata.com/2016/12/companies-using-r.html) puedes encontrar un listado m√°s completo. 


Una de las mayores ventajas de usar R es que puedes usar Rmarkdown y Shiny. Lo veremos, pero [aqu√≠](https://rfortherestofus.com/2019/03/r-killer-feature-rmarkdown/) tienes un post que explica sus ventajas. Un ejemplo de utilizaci√≥n es [est√° aplicaci√≥n de seguiminento del covid](https://calcat.covid19.ca.gov/cacovidmodels/) que ha implementado el departamento of Public Health de California.

Si te gustan los rankings de lenguajes de programaci√≥n, [aqu√≠](https://redmonk.com/sogrady/2020/02/28/language-rankings-1-20/) tienes uno, de enero de 2020, en el Phyton est√° en segundo lugar mientras que R est√° en el puesto 13. Esto es lo que que se dice de R:

>  In our first run of these rankings, R placed 17th. All these years later it jumps two spots from the last quarter‚Äôs edition up to #13. In the interim, it has ranked as high as 12th but mostly commonly is found in the 13-15 range. Given the language‚Äôs specialized focus, this is likely its effective ceiling, but it‚Äôs also an illustration of the remarkable popularity of a language whose usage is restricted for all intents and purposes to a single domain ‚Äì those who work with and operate on data. R‚Äôs success is an example of the power of an academia-supported community to elevate a language beyond its expected threshold, and it is notable that the aforementioned growth of Python and its expansion into data analytics has not observably come at the expense of traction in R.


Mientras reescribo estas notas, julio de 2020, R ha subido al puesto 8, mientras que Phyton est√° en el tercero. El ranking m√°s actual puedes verlo [aqu√≠](https://www.tiobe.com/tiobe-index/).


### ¬øEs complicado aprender R?


¬øAprender R es complicado? No, bueno ... ya responder√© a esto en clase. No mires el siguiente tweet:



```{r, echo = FALSE}
tweetrmd::tweet_embed("https://twitter.com/rogierK/status/730863729420701697", theme = "light", align = "center", dnt = TRUE, plain = TRUE, maxwidth = 400)
```


<br>

Aunque la verdad, esta dificultad/rareza de R es cosa de otros tiempos. Con el tidyverse todo es m√°s f√°cil y brillante. Como muestra el tweet de Chris Albon, un miembro destacado de la comunidad Phyton. Merece la pena echarle un ojo a algunas de las respuestas al tweet.


<blockquote class="twitter-tweet"><p lang="en" dir="ltr">I used R for many years but whenever I hear about it now it feels like I watched R season one and now it is on a spin-off based on the characters of season 13.</p>&mdash; Chris Albon (\@chrisalbon) <a href="https://twitter.com/chrisalbon/status/1225592440230481920?ref_src=twsrc%5Etfw">February 7, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

<br>



### Algunos sitios a visitar


- [Rweekly](https://rweekly.org/). Cada semana env√≠an un archivo con los mejores an√°lisis hechos con R esa semana. Tienes que apuntarte [aqu√≠](https://feedburner.google.com/fb/a/mailverify?uri=rweekly&loc=en_US)

- [Rbloggers](https://www.r-bloggers.com/). Un agregador de blogs relacionados con R.

- [R Views](https://rviews.rstudio.com/). Es un blog asociado a RStudio. Cada mes saca un post donde eligen los mejores 40 paquetes de ese mes; por ejemplo, [aqu√≠](https://rviews.rstudio.com/2019/08/29/july-2019-top-40-r-packages/) tienes el de julio de 2019.

- [swirl](https://swirlstats.com/). swirl teaches you R programming and data science interactively, at your own pace, and right in the R console!


<br>

<br>
