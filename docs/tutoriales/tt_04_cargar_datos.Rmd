---
title: "Importar (y exportar) datos en R"
author: "Pedro J. Pérez"
date: "`r format(Sys.time(), '%d %B %Y')`"
#date: "2020/03/05 (updated: `r Sys.Date()`)"
output:
  html_document:
    css: !expr here::here("assets", "styles_pjp.css") #-https://stackoverflow.com/questions/56681879/how-to-use-here-for-paths-to-css-before-body-and-after-bod
    theme: paper
    highlight: textmate
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: true
      smooth_scroll: true
    self_contained: true
    number_sections: false
    #code_folding: show
    df_print: kable
    code_download: true
editor_options:
  chunk_output_type: console
#bibliography: "`r here::here('assets', 'biblio.bib')`"  #- joooder. single quotes https://community.rstudio.com/t/use-here-here-function-in-yaml-option/18667/9
---

```{r, include = FALSE}
library(tidyverse)
```

```{r chunk-setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE,
                      #results = "hold",
                      cache = FALSE, cache.path = "/caches/", comment = "#>",
                      #fig.width = 7, #fig.height= 7,
                      #out.width = 7, out.height = 7,
                      collapse = TRUE,  fig.show = "hold",
                      fig.asp = 7/9, out.width = "60%", fig.align = "center")

#- para mejorar los gráficos, bueno en realidad para que se vean igual en distintos SO
#- https://www.jumpingrivers.com/blog/r-knitr-markdown-png-pdf-graphics/
knitr::opts_chunk$set(dev = "png", dev.args = list(type = "cairo-png"))
```

```{r options-setup, include = FALSE}
options(scipen = 999) #- para quitar la notación científica
options("yaml.eval.expr" = TRUE) #- https://github.com/viking/r-yaml/issues/47  (lo puse x el pb con el warning) En realidad creo que mejor sería ponerlo en RProfile
```


```{r klippy, echo = FALSE}
klippy::klippy(position = c("top", "right")) #- remotes::install_github("rlesur/klippy")
```

-----------------

# 1. Intro

<br>

Ya sabemos que R es un lenguaje de programación orientado al análisis de datos. Lo primero que tenemos que hacer para empezar un análisis con datos en R es, evidentemente, cargar los datos en R. En realidad en este tutorial aprenderemos a **importar y exportar datos en diferentes formatos**.


Hay datos de muchos tipos y en muchos formatos: imágenes, texto, ... , pero en el curso nos centraremos en conjuntos de datos que pueden almacenarse en hojas de calculo, ya que esta es la forma habitual de trabajar con datos en las ciencias sociales.

<br>

Utilizando un diagrama de [este fantástico libro](http://r4ds.had.co.nz/), estamos en la casilla de salida de cualquier análisis de datos.


```{r,  echo = FALSE, eval = TRUE, fig.cap = "Primera etapa: Importar datos (http://r4ds.had.co.nz/)", fig.asp = 4/2, out.width = "80%", fig.align = "center"}
knitr::include_graphics(here::here("imagenes", "tt_04_img_01_cargar-datos.png"))
```



Para importar/exportar datos vamos a usar funciones de varios packages, así que tenemos que saber como acceder a su documentación, pero esto ya se vio en el tutorial sobre R-base.



<br>

Cargar datos es una de las primeras frustraciones de alguien que comienza a aprender R. Generalmente piensan: pero si en Excel/SSPSS sólo tengo que pinchar en el fichero!! Como mucho tengo que usar los menús desplegables!! 
En R esto también es posible: R tiene 2 formatos de datos propios que se abren simplemente haciendo doble click y la última versión de RStudio también permite cargar datos a través de menús; pero .... no os acordáis de la Investigación Reproducible!! 


<br>

####  RStudio permite cargar datos a través de menús, pero ...

RStudio permite cargar datos a través de menús (` File > Import Dataset `). Por menús se pueden cargar datos CSV, EXCEL, SPSS, SAS y STATA. En el curso pensamos que hay que hacerlo todo a través de scripts; por lo tanto, no usaremos los menús.

Al usar los menús de RStudio para importar datos en realidad se está llamando a unas funciones que son las que importan realmente los datos; ademas, para importar datos a través de los menús, RStudio no usa las funciones de R-base sino las funciones de dos packages **`readr`** y **`haven`**. En el curso seguiremos este enfoque y usaremos `readr` y `haven`, además de algún otro pkg, para importar y exportar datos.

Haremos un poco más de énfasis en la importación de datos ya que si usas R, lo normal es hacer todo el análisis (incluso la generación de informes) en el entorno R. 

<br>

-------------------------

<br>


#### ¿Por qué no usar R-base? [OPCIONAL]

Ya hemos dicho que RStudio carga datos a través de menús, pero no utiliza las funciones de R-base, sino de otros paquetes, concretamente `readr` y `haven`

R tiene ya unos 20 años. Las funciones de R-base se construyeron pensando en los estadísticos de hace 20 años (hoy se llamarían analistas de datos). Modificar las funciones de R-base haría que código antiguo dejase de funcionar, así que la mayoría de avances y mejoras se producen en los packages. 

Las funciones de `readr` tratan de ser lo mas parecidas a las funciones equivalentes de R-base pero en cierto sentido mejorándolas y haciéndolas más consistentes; por ejemplo para leer datos CSV la función de R-base es `read.csv()`; mientas que la función equivalente de "readr" es `read_csv()`. Las dos hacen lo mismo, leer datos en formato CSV, pero las nuevas funciones tienen algunas ventajas:  

  - Son más rápidas.
  
   - Encajan más en el workflow/paradigma de la investigación reproducible. Por ejemplo, algunas de las funciones de R-base heredan algunas opciones del sistema operativo y las variables de entorno, haciendo posible que un script que funciona en un ordenador no funcione en otro. (Esto aún puede pasarnos a nosotros en el curso. Esperemos que no!!).

  - En lugar de generar data.frames, producen tibbles. Las tibbles son en realidad data.frames pero con algunas particularidades. 
  
  - Las tibbles o "data frames tuneados" tienen unas ciertas ventajas: no convierten por defecto vectores de texto en factores, no usan row names, ni transforman los column names (estás 3 cosas que sí hacen los "data.frames tradicionales" pueden provocar algunas complicaciones, así que mejor tener herramientas que las sorteen).



<br>


------------------------

#### Datos precargados en R [OPCIONAL]

R-base viene con muchos datos precargados; concretamente en el pkg de R-base llamado `datasets`. Además muchos packages contienen también conjuntos de datos. Para ver los datos que tenemos precargados y disponibles en R se usa la función `data()`:

```{r, echo = T, eval = F}
#- se abrirá una ventana con el listado de datos disponibles
data()  
#!! guardamos el listado de datos en un data.frame llamado "aa"
aa <- as.data.frame(data()[[3]]) 
```

<br>

Si queremos ver los datos que hay en un package concreto usaremos `data(package = "pkg_name")`

```{r, echo = T, eval = F}
#- vemos en una ventana el listado de datos disponibles en el pkg ggplot2
data(package = "ggplot2")
#!! guardamos el listado de datos del pkg ggplot2 en el df "aa"
aa <- as.data.frame(data(package = "ggplot2")[[3]]) %>% select(-2)
#!! guardamos el listado de datos del pkg ggplot2 en una tibble
aa <- as_tibble(data(package = "ggplot2")[[3]]) %>% select(-2) 
```


<br>

Por ejemplo, el package `ggplot2` tiene los siguientes conjuntos de datos:


```{r, echo = F, eval = T}
#- guardamos el listado de datos del pkg ggplot2 en una tibble
library(tidyverse)
aa <- as_tibble(data(package = "ggplot2")[[3]]) %>% select(-2) 
#- mostramos aa como tabla
knitr::kable(aa)
```

<br>

Podemos ver todos los datasets que hay en los packages que tenemos en nuestra librería de packages de nuestro ordenador:

```{r, echo = TRUE, eval = FALSE}
# !! abre una ventana donde se ve el listado de todos los datasets que contienen los packages de nuestra librería
data(package = .packages(all.available = TRUE))
```

<br>

-------------------

<br>


# 2. Tipos de datos que veremos

<br>

Introduciremos funciones para importar/exportar datos de los siguientes formatos:

<br>

- Datos en formato texto (o tabulares)

    - CSV: `.csv` (comma separated values o , en castellano, datos separados por comas)
    - otros datos en formato texto
    
<br>

-  Formatos de otros programas (software propietario)

    - EXCEL: `.xls` y `.xlsx`
    - SPSS:   `.sav` y `.por`
    - STATA: `.dta`
    - SAS:  `.sas`

<br>

- Formatos propios de R

    - R objects: `.RData` o `.rda`
    - Serialized R objects: `.rds`

<br>

- Otros Formatos

    - JSON
    - XML
  
<br>
  
Además aprenderemos como bajar datos a través de APIs:

  - Eurostat
  - INE
  - Banco Mundial



<br>

----------------


#### Estrategia que seguiremos para aprender a Importar/Exportar datos

Lo que vamos a  hacer en este tutorial para aprender a importar (y exportar) datos en R es elegir un fichero de datos precargado en R y exportarlo a un determinado formato para luego importar el archivo generado o exportado. Repetiremos esto para distintos formatos de datos. 

Da igual que archivo de datos usar, pero por fastidiar a Vicente (y porque es un fichero ligero) utilizaremos un conjunto de datos famoso: "el [`iris`](https://es.wikipedia.org/wiki/Iris_flor_conjunto_de_datos) dataset" que fue utilizado por Ronald Fisher. Iris contiene 150 observaciones de 5 variables: mediciones de 5 características sobre 150 flores de la especie Iris.


<br>

--------------------

#### ¿Cómo podemos ver que variables (y de que tipo) hay en un df?

Supongamos que ya hemos cargado un conjunto de datos y que está almacenado en un df, ¿cómo podemos ver que variables (y de que tipo) hay en el df?

Vamos a ver los nombres de las variables (columnas) del dataset iris:

```{r, echo = TRUE, eval = TRUE}
# names() muestra los nombres de las variables de un dataframe
names(iris)
```
No nos hace falta, pero veamos los primeros valores de iris:

```{r, echo = TRUE, eval = TRUE}
# head() muestra las n (ne este caso 4) primeras filas de un dataframe
head(iris, n = 4)
```

La función `summary()`, nos hace un resumen (!) del df

```{r, echo = TRUE, eval = TRUE}
# Fíjate que la variable "Species" no tiene media, ni mínimo, ni max. ... es porque es un factor
summary(iris)
```




<br>

**SIEMPRE-SIEMPRE** hay que chequear de que clase son las variables que contiene el df.


```{r, echo = TRUE, eval = TRUE}
#- ver la estructura del df. Visualizaremos los nombres y el tipo de las variables
str(iris)
```

También podéis usar la función `skim()` del package  `skimr`.


```{r, echo = TRUE, eval = FALSE}
#devtools::install_github("ropenscilabs/skimr")
library(skimr)
skim(iris)
```


```{r , echo = FALSE, eval = TRUE, fig.asp = 4/2, out.width = "80%", fig.align = "left"}
knitr::include_graphics(here::here("imagenes", "tt_04_img_03_output-skimr.png"))
```




<br>

**Vamos YA a exportar (e importar) "iris" a diferentes formatos. Empezamos!!**

<br>

--------------------

<br>


# 3. Datos tabulares (o de texto)

<br>

Estamos acostumbrados a visualizar datos en **formato tabular**; es  decir, como una tabla. Generalmente **las columnas son variables y las filas son observaciones** de esas variables para diferentes unidades de análisis ("individuos"). 

Las columnas **se separan con un carácter** (generalmente la coma) y las filas con un salto de linea.

Podemos pensar que dependiendo de como se separen las observaciones tenemos distintos tipos de datos tabulares, pero en realidad su estructura es similar: variables en columnas y las observaciones de un individuo separadas por una marca o carácter. Este carácter puede ser un espacio, un tabulador, una coma, punto y coma etc... El formato tabular mas extendido es el **CSV**, donde las observaciones están separadas por comas. 


Estos datos se pueden visualizar en los editores de texto y por eso también se llaman datos en formato texto.

Podemos pensar que hay 2 grupos de datos tabulares:

  - delimitados por caracteres
  - de anchura fija  

El package `readr` lee datos tabulares con las siguientes funciones:

- si los datos están delimitados por caracteres utiliza: `read_delim()`, `read_csv()`, `read_tsv()` ...
- si los datos son de anchura fija: `read_fwf()` y `read_table()`

Sólo veremos como importar/exportar datos tabulares del primer tipo; es decir, separados por caracteres. Comenzaremos con el formato CSV que es el más utilizado.

<br>

------------------------------

## CSV

CSV significa "comma separated data". En realidad CSV es un caso particular de "tabular o text data"

Recordad que tenemos que exportar el dataframe `iris` a formato CSV y luego importarlo.

Para exportar `iris` a un fichero en formato `CSV` utilizaremos la función `write_csv()`: solo hay que decirle el objeto que queremos exportar (en este caso un df "iris") y el nombre (junto con la ruta) del archivo donde queremos guardarlo.

Podemos especificar la ruta completa. Por ejemplo:

```{r, echo = T, eval = F}
#- exporta en formato CSV el df iris al fichero "iris.csv" 
#- Cuidado!! es una ruta absoluta. No funcionará en todos los ordenadores
write_csv(iris, path = "C:/Users/perezp/Desktop/iris.csv")
```

<br>

En realidad no hace falta especificar la ruta completa. Si solo especificamos el nombre del archivo, R lo guardará en el directorio de trabajo. 

```{r, echo = T, eval = F}
#- exporta en formato CSV el df iris al fichero "iris.csv". Como no se especifica la ruta, se grabará en el directorio de trabajo 
write_csv(iris, path = "iris.csv")
```


Recuerda que para saber cual es tu directorio de trabajo puedes usar la función `getwd()` y puedes cambiarlo desde los menús de RStudio o con `setwd()`. Por ejemplo:

```{r, echo = TRUE, eval = FALSE}
#- almacenamos en el objeto "path_wd" la ruta del directorio de trabajo del ordenador que estás usando
path_a_mi_wd <- getwd() 

#- Podemos fijar  el directorio de trabajo donde queramos. Por ejemplo:
setwd("C:/Users/perezp/Desktop/Mis_datos/")  
#- en tu ordenador no funcionará porque tu ordenador no tiene esa ruta o estructura de carpetas

#- fijamos el directorio de trabajo (aunque en realidad no hace falta porque esa ruta almacenada en  "path_a_mi_wd" ya era ese el directorio de trabajo
setwd(path_a_mi_wd)      
```


<br>

Recomendamos trabajar con Rprojects y guardar los ficheros de datos en una carpeta llamada `/datos/`. 


Por lo tanto, para exportar los datos de "iris" en la subcarpeta `/datos/pruebas/` dentro del proyecto, hay que hacer lo siguiente:

```{r, echo = TRUE, eval = FALSE}
#- exporta en formato .csv el df iris al fichero "iris.csv". Se guardará en la subcarpeta "datos/pruebas/" del proyecto
write_csv(iris, "./datos/pruebas/iris.csv")
```

Si queremos, podemos poner explícitamente los argumentos (o parámetros) de la función `write_csv()`:


```{r, echo = TRUE, eval = FALSE}
#- Otra vez exportamos en formato .csv el df iris. Esta vez explicitamos las opciones o parámetros de la función
write_csv(iris, path = "./datos/pruebas/iris.csv", col_names = TRUE)
```



```{r, echo = FALSE, eval = TRUE}
#- para que se pueda correr en .Rmd en otra carpeta que no se la raiz
#- Otra vez exportamos en formato .csv el df iris. Esta vez explicitamos las opciones o parámetros de la función
write_csv(iris, path = here::here("./datos/pruebas/iris.csv"), col_names = TRUE)
```




<br>

Bien, ya hemos exportado "iris" a un fichero en formato CSV, ahora vamos a importarlo.


<br>

Para importar los datos del fichero "iris.csv" hacemos lo siguiente:


```{r, echo = TRUE, eval = FALSE}
#- importamos los datos del fichero "iris.csv" y los guardamos en un objeto que llamamos "iris_imp_csv". Recuerda que acabamos de exportar "iris" a la carpeta "/datos/pruebas/" dentro del Rproject
iris_imp_csv <- read_csv("./datos/pruebas/iris.csv")
```


<br>

Así de sencillo!! Además la mayoría de programas permiten leer y exportar datos en CSV; así que si trabajamos con otro software (Excel, SPSS ...), siempre podemos pasar nuestros datos a R exportándolos a CSV; y desde R podemos hacer lo mismo. 

<br>


#### Algunas opciones de `read_csv()` que conviene conocer

A veces los datos tienen ciertos problemas que hay que arreglar; por lo que conviene conocer algunas opciones de `read_csv()`:

- **col_names:** read_csv() asume que la primera fila contiene los nombres de las variables. Esto puede cambiarse con `col_names = FALSE`. Puedes proveer nombres a las variables (o columnas) con `col_names = c("X1", "X2")`

- **skip:**read_csv() por defecto importa todas las filas del archivo, pero puedes hacer que comience a importar en la fila que quieras con `skip = n`

- **na:** En algunos ficheros con datos tabulares los NAs se especifican con algún carácter. Esto podemos tratarlo al leer los datos con el argumento   `na = "xxx"`




Por ejemplo, el chunk que ves abajo utiliza read_csv() para cargar el fichero "my_fichero.csv". Comienza a importar datos desde la quinta columna,  trata los valores -44 y $ como NAs y provee un vector con los nombres que queremos para las variables (o columnas)

```{r, echo = TRUE, eval = FALSE}
mis_datos <- read_csv("my_fichero.csv", skip = 5, na = c("-44", "$"), col_names = c("X1", "X2", "YY", "X4", "ZZ"))
```




------------------------

## Otros datos tabulares 

En realidad, todos los datos tabulares (**separados por caracteres**) son muy similares. ¡Solo se diferencian en el carácter que hace de separador. 

El package "readr" tiene una función especifica para cada tipo de datos tabulares. Por ejemplo, si el separador es un punto y coma, la función para importar estos datos es `read_csv2()`; si el separador es un tabulador, la función es `read_tsv()`. Pero también tiene una función genérica que sirve para cualquier tipo de separador: `read_delim()` . Obviamente usaremos estas funciones.


Por ejemplo, podemos cargar el fichero "my_iris_exportado.csv" que hemos exportado anteriormente utilizando la función genérica `read_delim()`, solo hay que decirle que el separador es una coma. Se lo decimos con la opción `delim = ","`. Veámoslo:


```{r, echo = TRUE, eval = FALSE}
#- importamos los datos del fichero "iris.csv" y los guardamos en un objeto que llamamos iris_imp_csv_2. Fíjate en el argumento 'delim'
iris_imp_csv_2 <- read_delim("./datos/pruebas/iris.csv", delim = ",")
```

Como el formato tabular mas extendido es el CSV; en general, no tendremos necesidad de exportar datos tabulares separados por caracteres distintos a la coma, pero si quisiéramos hacerlo, podríamos hacerlo con `write_tsv()` o con `write_delim()`:


```{r, echo = TRUE, eval = FALSE}
#- exportamos iris en formato tabular separado por punto y coma. 
write_delim(iris, "./datos/pruebas/iris_2.txt", delim = ";")
#- exportamos iris en formato tabular separado por tabuladores 
write_delim(iris, "./datos/pruebas/iris_3.txt", delim = "\t")
#- exportamos iris en formato tabular separado por un espacio en blanco 
write_delim(iris, "./datos/pruebas/iris_4.txt", delim = " ")
```

<br>

Si quisiéramos importarlos, tendríamos que hacer:


```{r, echo = TRUE, eval = FALSE}
#- exportamos iris en formato tabular separado por punto y coma. 
read_delim("./datos/pruebas/iris_2.txt", delim = ";")
#- exportamos iris en formato tabular separado por tabuladores 
read_delim("./datos/pruebas/iris_3.txt", delim = "\t")
#- exportamos iris en formato tabular separado por un espacio en blanco 
read_delim("./datos/pruebas/iris_4.txt", delim = " ")
```



<br>
<br>


--------------------------

<br>

# 4. Formatos propietarios

Hasta que R haga desparecer a SPSS, Stata,  ..... `r emo::ji("biceps")`,  aún será necesario importar algún fichero en formatos de software propietario como los de Excel, SAS, Stata , SPSS y Eviews


Normalmente lo que necesitaremos es importar datos en esos formatos, sólo alguna vez tendremos que exportarlos, ya que todos estos programas pueden leer datos en CSV.


Lo que sí puede resultarnos útil es exportar datos en formato .xls, ya que Excel es muy útil  para visualizar datos en formato tabular y también porque mucha gente prefiere (o solo sabe) leer/analizar datos en Excel.


<br>

------------------------

<br>

## Excel

#### Exportar a excel

Hay varios packages que graban datos en formato .xls. Pero el más sencillo es el package `xlsx`. Veámoslo:

```{r, echo = T, eval = FALSE}
library(xlsx)
write.xlsx(iris, "./datos/pruebas/iris.xlsx")
```


La función `write.xlsx()` permite especificar el nombre del libro y alguna cosa más; por ejemplo:


```{r, echo = T, eval = FALSE}
# library(xlsx)
write.xlsx(iris, "./datos/pruebas/iris.xlsx", sheetName = "IRIS", row.names = FALSE)
```

La función `write.xlsx()` permite añadir datos a un archivo .xlsx preexistente; para ello tenemos que usar la opción `append = TRUE`:


```{r, echo = T, eval = FALSE}
# library(xlsx)
write.xlsx(iris, "./datos/pruebas/iris.xlsx", sheetName = "IRIS_2", append = TRUE)
```

<br>

El paquete `xlsx` depende de Java. No suele haber problemas, pero si los tuvieses, el package `writexl` no tiene ninguna dependencia. Tendrías que hacer lo siguiente:


```{r, echo = TRUE, message = FALSE, eval = FALSE}
library(writexl)
write_xlsx(iris, "./datos/pruebas/iris8.xlsx")
```

<br>


#### Importar archivos en formato excel

También hay varios paquetes, pero usaremos el mismo que usa RStudio en sus menús: `readxl`


**`readxl`** permite leer ficheros `.xls` y `.xlsx`. Por ejemplo:


```{r, echo = T, eval = FALSE}
# library(readxl)
iris_imp_xls <- read_excel("./datos/pruebas/iris.xlsx")
```

<br>

Podemos especificar el libro que queremos abrir, ya sea especificando su nombre o su posición en el fichero


```{r, echo = T, eval = FALSE}
# library(readxl)
iris_imp_xls <- read_excel("./datos/pruebas/iris.xlsx", sheet = 2)
iris_imp_xls <- read_excel("./datos/pruebas/iris.xlsx", sheet = "IRIS_2")
```


La función `read_excel()` tiene más posibilidades; como ejemplo, la opción `skip = 4` permite empezar a importar a partir de la cuarta fila.

<br>

Si queremos importar todos los libros (o sheets) de un archivo Excel, podemos hacerlo así:


```{r, echo = T, eval = FALSE}
# library(readxl)
# (!!!)
IRIS_list <- lapply(excel_sheets("./datos/pruebas/iris.xlsx"), read_excel, path = "./datos/pruebas/iris.xlsx")
```

Hemos guardado los 2 sheets del archivo "./datos/pruebas/iris.xlsx" en un objeto R llamado `IRIS_list`. Este objeto es una lista con 2 elementos. cada elemento contiene los datos de cada uno de los 2 sheets. Podemos verlo con `str()`:


```{r, echo = T, eval = FALSE}
# (!!!)
str(IRIS_list)
```

Si quisiéramos recuperar los datos en el formato en el que estamos habituados (dataframes) lo haríamos así:



```{r, echo = T, eval = FALSE}
# (!!!)
primer_iris  <- IRIS_list[[1]]
segundo_iris <- IRIS_list[[2]]
```

<br>

---------------------

<br>

##  Otros formatos propietarios

Veremos SPSS, Stata y SAS.

Utilizaremos el mismo package que usa RStudio: `haven`. Si necesitásemos importar otro tipo formato es muy posible que se pueda hacer con los los packages `foreign` y `rio`

<br>

----------------

### SPSS


#### Exportación a SPSS (formato `.sav`)


```{r, echo = T, eval = FALSE}
# library(haven)
write_sav(iris, "./datos/pruebas/iris.sav")
```
<br>

#### Importacion de ficheros `.sav` (tb `.por`)


```{r, echo = T, eval = FALSE}
# library(haven)
iris_imp_spss <- read_spss("./datos/pruebas/iris.sav")
```


<br>

----------------


### Stata


#### Exportación a STATA (formato `.dta`)

Se puede exportar con `haven` (pero no permite labelled data!!), así que mejor hacerlo esta vez con el package `foreign`

```{r, echo = T, eval = FALSE}
# library(foreign)
write.dta(iris, "./datos/pruebas/iris.dta")
```


<br>

#### Importacion de ficheros STATA (`.dta`)


```{r, echo = T, eval = FALSE}
# library(haven)
iris_imp_stata <- read_stata("./datos/pruebas/iris.dta")
```



<br>

----------------


### SAS



#### Exportación a SAS 

**`haven`** exporta bien a SAS; pero ... los nombres de las variables no pueden contener puntos, así que usamos otro fichero de datos `mtcars`. Podríamos haber cambiado el nombre de las columnas de iris (quitando los puntos), pero lo dejamos para el próximo tutorial.

```{r, echo = T, eval = FALSE}
# mtcars es un dataset  del pkg ggplot2, asi que ggplot2 debe estar cargado
# library(ggplot2)
# library(haven)
write_sas(mtcars, "./datos/pruebas/mtcars.sas") 
```



<br>

#### Importacion de ficheros SAS 


```{r, echo = T, eval = FALSE}
# library(haven)
mtcars_imp_sas <- read_sas("./datos/pruebas/mtcars.sas")
```


<br>

----------------

<br>

# 5. Formato(s) propios de R

Guardar datos en formatos como txt, csv o Excel es lo más habitual si quieres abrir estos datos en otros programas; pero al grabar en estos formatos guardas los datos, PERO no guardas la estructura de los datos; es decir, si por ejemplo una columna la has definido como un factor o como integer, esta información se perderá. En estos casos, una solución es usar el formato propio de R. 

Hay dos posibilidades:

  - si quieres grabar un solo objeto, es preferible hacerlo como `Rds`
  - si quieres grabar varios objetos tienes que hacerlo como `RData` o abreviado como `Rda`

<br>

----------------

## RData

**RData** (o Rda) es un formato especifico de R, pero tiene dos ventajas:

  - es bastante eficiente 
  - permite guardar varios objetos en un único archivo

<br> 

Para **exportar** `my_iris` a un fichero en formato `.RData` utilizaremos la función `save()`: solo hay que decirle el objeto que queremos exportar (en este caso un df/tibble llamado "my_iris") y el nombre (junto con la ruta) del archivo donde queremos guardarlo.


```{r, eval = FALSE}
#- exporta en formato .RData el df my_iris al fichero "iris.RData". 
save(iris, file = "./datos/pruebas/iris.RData")
```



<br>
El formato `.RData` tienen la ventaja de que puedes guardar varios objetos a la vez. 


```{r, echo = T, eval = FALSE}
save(mtcars, iris,  file = "./datos/pruebas/mtcars_and_iris.RData")
```

Incluso puede guardar  todos los objetos de la sesión. Mejor no hacerlo

```{r, echo = T, eval = FALSE}
save(list = ls(all = TRUE), file= "./datos/pruebas/all_objects.RData")
```

O todo el espacio de trabajo:

```{r, echo = T, eval = FALSE}
save.image(file = "./datos/pruebas/my_work_space.RData")
```

para luego cargarlos con:


```{r, echo = T, eval = FALSE}
load("./datos/pruebas/all_objects.RData")
load("./datos/pruebas/my_work_space.RData")
```



<br>

Para cargar o **importar** datos en formato `.RData` basta con arrastrarlos dentro de RStudio, o seguir la ruta de menús ` File > Open File ` pero para hacerlo en un script se hace así:

```{r, eval = FALSE}
#- importamos el fichero "my_data2.RData"
load(file = "./datos/pruebas/iris.RData")
```

<br>


Un posible pega es que al cargar datos con `load()` se cargan todos los datos que guardaste y además se cargan en el espacio de trabajo con el mismo  nombre con que los guardaste. Esto puede ser una pega pues es posible que haya un objeto que se llame igual que un objeto con el que estás trabajando en RStudio.




## RDS (Serialized R objects)

Una "desventaja" del formato `RData` es que al importar un fichero .RData, los objetos que contiene se cargan siempre con el nombre con el que fueron grabados. ¿Qué más da? Bueno, puede parecer que no es muy importante, pero a veces esto puede limitar el workflow, así que muchas veces es preferible grabar como `.RDS` con la función `write_rds()`. La pega es que está función solo permite guardar un objeto.

Para **exportar** iris a formato RDS hacemos: 

```{r, echo = T, eval = FALSE}
write_rds(iris, "./datos/pruebas/iris.rds")
```

<br>

Para leer o **importar** datos RDS (hay que asignarle un nombre, que puede ser o no el nombre original) hacemos:

```{r, echo = T, eval = FALSE}
iris_imp_rds <- readRDS("./datos/pruebas/iris.rds")
```




<br>

-----------------------

<br>


# 6. Otros formatos

<br>

Los formatos más frecuentes (al menos en nuestra área) continúan siendo los .csv, .xls, ... PERO existen muchos otros formatos. 


Hay 2 formatos que es bueno, al menos, saber que existen, porque cada vez son más frecuentes: 

  - JSON (JavaScript Object Notation) 
  - XML (Extensible Markup Language). 
  
  
Para JSON, se recomienda usar el paquete `jsonlite` y para XML, `xml2`.

<br>


#### El package `rio` es la navaja suiza del I/O data en R

Si hay algún formato de datos que quieras abrir en R y no lo hayamos tratado, probablemente el package `rio` sea capaz de importarlo. [Aquí](https://github.com/leeper/rio#supported-file-formats) tienes la lista de los formatos que puede importar; además todos ellos con una sola función (`import()`). Para exportar hay que usar la función `export()`


El paquete `rio` es muy fácil de usar, pero en realidad lo que hace es llamar/utilizar otros paquetes para hacer el trabajo. Por ejemplo para exportar/importar a SPSS usa el paquete `heaven`, para Matlab usa el paquete `rmatio`, así que si quieres importar datos de Matlab tendrás que tenerlo instalado. Al cargar el paquete `rio` con `library(rio` nos avisará de si nos falta algún paquete y si queremos los instalará por nosotros con la función `rio::install_formats()`


Veámos como funciona `rio`. Para ello primero **exportaremos** el fichero de datos `mtcars` adiferentes formatos:

```{r, echo = TRUE, eval = FALSE}
library(rio)
export(mtcars, "./datos/pruebas/mtcars.csv")   # comma-separated values
export(mtcars, "./datos/pruebas/mtcars.rds")   # R serialized
export(mtcars, "./datos/pruebas/mtcars.sav")   # SPSS
export(mtcars, "./datos/pruebas/mtcars.json")  # JSON
export(mtcars, "./datos/pruebas/mtcars.arff")  # Weka Attribute-Relation File Format
```

<br>

Además permite exportar y **comprimir los datos directamente**:

```{r, echo = TRUE, eval = FALSE}
library(rio)
export(mtcars, "./datos/pruebas/mtcars.tsv.zip") # TSV & Zip it
```

<br>

Para **importar** los ficheros que hemos exportado previamente:


```{r, echo = TRUE, eval = FALSE}
library(rio)
mtcars_csv  <- import("./datos/pruebas/mtcars.csv")  # CSV
mtcars_spss <- import("./datos/pruebas/mtcars.sav")  # SPSS (.sav)
```


Como curiosidad decir que `rio` importa los datos como data.frames, no como tibbles, pero puedes forzarlo con:

```{r, echo = TRUE, eval = FALSE}
library(rio)
mtcars_csv  <- import("./datos/pruebas/mtcars.csv", setclass = "tibble")  # CSV
```

En [este post](http://ritsokiguess.site/docs/2018/03/25/today-on-twitter-i-learned/) también explican que `rio` puede ser una alternativa a `rvest` y/o `xml2` para importar tablas html en internet. Por ejemplo:

```{r, echo = TRUE, eval = FALSE}
my_url <- "http://www.scoresway.com/?sport=soccer&page=competition&id=8"
table <- import(my_url, format = "html", which = 2)
```




Si tampoco `rio` puede leer el formato que necesitas, es muy probable que alguien haya escrito un package para hacerlo; tendrás que ver si existe buscando en internete.


Recientemente ha aparecido otro meta-pkg para leer datos. Es el pkg `readit`. Aún no lo he usado pero, por varias razones, no quiero olvidarme de él. Puedes verlo [aquí](https://cran.r-project.org/web/packages/readit/index.html)

<br>

--------------------

<br>


# 7. Descargar datos de internet

<br>

Hay muchísimos datos en internet para descargar; siempre podemos descargarlos usando el navegador, PERO la filosofía del curso es (si podemos) hacerlo todo desde R/RStudio

Desde RStudio, podemos descargar datos con las mismas funciones que usábamos para cargar en el entorno de trabajo los  datos que teníamos en nuestro PC. La única diferencia consiste en que, en lugar de proporcionar la ruta al fichero, tendremos que proporcionar la ruta de internet. Por ejemplo:

<br>

```{r, echo = TRUE, eval = FALSE}
# cargamos los datos del fichero "bio260-heights.csv"
url <- "https://raw.githubusercontent.com/datasciencelabs/data/master/bio260-heights.csv"
datos <- read_csv(url)
```



<br>

A veces podemos necesitar hacer una copia de los datos a nuestro ordenador. En este caso, lo que yo haría es cargar los datos y luego exportarlos a .rds; pero también podemos hacerlo directamente con la función `download.file()`:

<br>

```{r, echo = TRUE, eval = FALSE}
# descargamos y almacenamos en nuestro PC los datos del fichero "bio260-heights.csv"
url <- "https://raw.githubusercontent.com/datasciencelabs/data/master/bio260-heights.csv"
destino <- "./datos/pruebas/bio260-heights.csv"
download.file(url, destino)
dat <- read.csv(destino)
```

<br>

A veces, la función de R-base `download.file` puede tener problemas si el protocolo es https. En estos casos, la función `dowload()` del pkg downloader puede solucionarlo:

```{r, echo = TRUE, eval = FALSE}
#install.packages("downloader")
library(downloader)
url <- "https://raw.githubusercontent.com/datasciencelabs/data/master/bio260-heights.csv"
filename <- basename(url)
destino <- paste0("./datos/pruebas/", filename)
download(url,destino)
dat <- read.csv(destino)
```


<br>

--------------------

<br>



# 8. API's y Web Scrapping

<br>

El proceso y acciones para recopilar información de la Web se conoce como [web scrapping](https://es.wikipedia.org/wiki/Web_scraping). Este proceso se puede hacer manualmente, pero lo habitual es automatizarlo utilizando software. Se puede acceder a los datos directamente pero actualmente es muy común hacerlo a través de APIs, ya que la mayoría de organismos/empresas tienen una o varias APIs. 


API significa "Aplication Programming Interface" y se puede entender como un mecanismo que nos permite interactuar (por ejemplo para hacer una petición de datos) con un servidor de internet. Por ejemplo, muchos bancos tienen APIs a las que se les pueden hacer peticiones, esto hace posible que se desarrollen apps para hacer ciertas operaciones bancarias; es decir, una API es un mecanismo que nos permite acceder y/o interactuar con determinadas funciones de un servicio web. 

Las APIs facilitan mucho la recopilación de datos al poderse acceder a ellas de forma programática ya que proveen de un proceso de acceso a ellos estandarizado: se envía una "http request" a la API y se reciben los datos en un determinado formato, generalmente JSON.

En el entorno R se pueden desarrollar paquetes para acceder a APIs; por ejemplo, vamos a utilizar el paquete de R `eurostat` para acceder a la API de Eurostat y descargar datos directamente en R. Veámoslo:

-------------------

<br>


## Eurostat 

Eursotat tiene una API que permite hacer peticiones de datos. Obviamente, para poder hacer peticiones de datos a través de su API has de conocer su sintaxis; si estás interesado puedes empezar [aquí](http://ec.europa.eu/eurostat/data/web-services). Nosotros accederemos a Eurostat a través del package [`eurostat`](https://ropengov.github.io/eurostat/). Si estas interesado en bajar datos de Eurostat es conveniente que uses esta [vignette](http://ropengov.github.io/eurostat/articles/eurostat_tutorial.html) y la [cheat sheet](http://ropengov.github.io/eurostat/articles/cheatsheet.html). Veamos un ejemplo:


Con la función `get_eurostat()` es suficiente para bajar una tabla de Eurostat con el porcentaje de empleos en sectores culturales:

```{r, echo = TRUE, eval = FALSE}
# install.packages("eurostat")
library("eurostat")
df <- get_eurostat("cult_emp_sex", time_format = 'raw', keepFlags = T)       #- bajamos los datos de la tabla "cult_emp_sex": empleo cultural por genero"
```


<br>

Un ejemplo más completo: descargaremos los datos de la tabla `hlth_silc_17` que contiene datos con la "esperanza de vida saludable" para diferentes años en los países de la UE.

```{r, echo = TRUE, eval = TRUE, results = "hide"}
# install.packages("eurostat")
library("eurostat")

#------------------ podemos buscar un  "tema" con la f. search_eurostat()
aa <- search_eurostat("employment", type = "all") 

#------------------ elegimos una tabla de Eurostat
my_table <- "hlth_silc_17"          #- elegimos una tabla; por ejemplo "hlth_silc_17": "Healthy life expectancy based on self-perceived health"
label_eurostat_tables(my_table)     #- da informacion sobre la Base de datos q estas buscando

#------------------ descargamos los datos con get_eurostat()
df <- get_eurostat(my_table, time_format = 'raw', keepFlags = T )       #- bajamos los datos de una tabla
df_l <- label_eurostat(df)        #- pone labels: Spain en lugar de su código (mas legible,menos fácil de programar)

#------------------ los arreglamos un poco 
library("tidyverse")
library("pjpv2020.01") #- remotes::install_github("perezp44/pjpv2020.01")
aa <- pjp_f_valores_unicos(df)       #- ver los valores unicos de cada columna
aa <- pjp_f_valores_unicos(df_l)     #- ver los valores unicos de cada columna
df <- label_eurostat(df, code = c("geo", "unit", "indic_he"))
```

Ahora vamos a fusionarlo con datos de los límites espaciales de cada país, para finalmente hacer un gráfico espacial .... PERO Eurostat o eurostat cambiaron su API, entonces ....  este chunk no funciona con la versión actual del paquete `eurostat`. Lo dejo por si aún funcionase en los ordenadores del aula.


```{r, echo = TRUE, eval = FALSE}
#- selecciono datos de 2016, Females, y HE_50 y después hago un cut de "values"
df_x <- df %>% filter(time == "2016") %>%  filter(sex == "Females") %>% filter(indic_he_code == "HE_50") %>% 
        mutate(cat = cut_to_classes(values, n = 7, decimals = 1))
mapdata <- merge_eurostat_geodata(df_x, resolution = "20", geocolumn = "geo_code") #- fusiono con geo data

ggplot(mapdata, aes(x = long, y = lat, group = group))+
  geom_polygon(aes(fill = cat), color = "black", size = .1)+
  scale_fill_brewer(palette = "RdYlBu") +
  labs(title = "Healthy life expectancy, 2016",
       subtitle = "Health expectancy in years at 50",
       fill = "Healthy life expectancy",
       caption = "(C) EuroGeographics for the administrative boundaries") + theme_light() +
  coord_map(xlim = c(-12, 44), ylim = c(35, 67))
```


Este sí funcionará con la nueva versión del pkg `eurostat`

```{r, echo = TRUE, eval = TRUE}
df_x <- df %>% filter(time == "2016") %>%  filter(sex == "Females") %>% filter(indic_he_code == "HE_50") %>% 
        mutate(cat = cut_to_classes(values, n = 7, decimals = 1))

geometrias <- get_eurostat_geospatial(resolution = "20", nuts_level = "0") #- ahora se bajan las geometrías y tienes que unirla tu con dplyr (Hay un Pb de encoding)
mapdata <- inner_join(geometrias, df_x, by = c("geo" = "geo_code"))

p <- ggplot(mapdata) +
  geom_sf(aes(fill = cat, geometry = geometry), color = "black", size = .1) +
  scale_fill_brewer(palette = "RdYlBu") +
  labs(title = "Healthy life expectancy, 2016",
       subtitle = "Health expectancy in years at 50",
       fill = "Healthy life expectancy",
       caption = "(C) EuroGeographics for the administrative boundaries") + theme_light() +
  coord_sf(xlim = c(-12, 44), ylim = c(35, 67)) 
p
```





<br>

------------------------------

<br>

## INE

<br>

¿El INE tiene API? Pues sí, [aquí](http://www.ine.es/dyngs/DataLab/manual.html?cid=45) puedes "verla", pero ...

Hace poco tuvimos que utilizar alguna tabla del INE y, en lugar de usar la API, nos bajamos los datos así:



```{r, echo = TRUE, eval = FALSE}
library("pxR")              #- para trabajar con datos PC-Axis
library("tidyverse")
library("pjpv2020.01")
file_name <- "http://www.ine.es/jaxiT3/files/t/es/px/4189.px?nocab=1"
df <- read.px(file_name) %>% as.data.frame() %>% as.tbl()   #- no funcionaba en 3.5 x $
aa <- pjpv2020.01::pjp_f_valores_unicos(df)     #- ver los valores únicos de cada columna
```


La verdad es que ahora (2019) hay un paquete que funciona/funcionaba bastante bien: <https://github.com/oddworldng/INEbaseR>

------------------------------

<br>



## Banco Mundial

<br>

Para acceder a la [API del Banco Mundial](https://datahelpdesk.worldbank.org/knowledgebase/topics/125589) hay, actualmente, 2 paquetes de R: [`WDI`](https://github.com/vincentarelbundock/WDI) y [`wbstats`](https://github.com/GIST-ORNL/wbstats). 

<br>

Podemos bajar datos del Banco Mundial con el paquete `WDI` así:

```{r, echo = TRUE, eval = FALSE}
#install.packages("WDI")
library("WDI")

#---- buscamos datos relacionados con GDP
aa <- WDIsearch('gdp')
aa <- WDIsearch('gdp.*capita.*constant')

#---- descargamos "NY.GDP.PCAP.KD":  GDP per capita (constant 2010 US$)
df <- WDI(indicator = "NY.GDP.PCAP.KD")
#---- podemos filtrar la querry
df <- WDI(indicator = "NY.GDP.PCAP.KD", country = c('MX','CA','US'), start = 1960, end = 2017)
```

<br>

Podemos bajar datos del Banco Mundial con el paquete `wbstats` así:

```{r, echo = TRUE, eval = FALSE}
#install.packages("wbstats")
library("wbstats")

#-------  lista de indicadores disponibles
aa <- wb_cachelist

#---- buscamos datos relacionados con GDP
aa <- wbsearch(pattern = "gdp")
aa <- wbsearch('gdp.*capita.*constant')

#---- descargamos "NY.GDP.PCAP.KD":  GDP per capita (constant 2010 US$)
df <- wb(indicator = "NY.GDP.PCAP.KD")

#---- podemos filtrar la querry
df <- wb(indicator = "NY.GDP.PCAP.KD", country = c('MX','CA','US'), startdate = 2000, enddate = 2017)
```


<br>

[Aquí](http://www.magesblog.com/2016/04/new-r-package-to-access-world-bank-data.html) tenemos un post en el que se usa el pkg wbstats para obtener datos y luego graficarlos.



------------------------------

<br>

## CrossRef


El paquete `rcrossref` permite acceder a varias de las APIs de [CrossRef](http://search.crossref.org/). ¿Que qué es CrossRef? Pues es un servicio que permite, entre otras cosas, facilitar el proceso de referenciar artículos en tus papers. [Aquí](http://www.neoscientia.com/crossref/) lo explican. Hay otro package para acceder a CrossRef: [`crminer`](https://github.com/ropensci/crminer) este pkg permite bajarse el texto del documento, pero claro, el texto ha de estar disponible!!


<br>

```{r, echo = TRUE, eval = FALSE}
#install.packages("rcrossref")
library("rcrossref")

#----- con cr_cn() podemos ver como se cita un determinado artículo en un determinado formato, por ejemplo "apa"
my_doi <- "10.1111/j.1467-6486.2012.01072.x"
cr_cn(dois = my_doi, format = "text", style = "apa")

cr_cn(dois = my_doi, format = "bibtex", style = "apa", locale = "en-US", raw = FALSE, progress = "none")

#------ con cr_citation_count() puedes ver el numero de citas de un artículo/DOI
aa <- cr_citation_count(doi = my_doi)

#------ con cr_abstract()
aa <- cr_abstract(doi = "10.1109/TASC.2010.2088091")

#------ con cr_journals() vemos journals
aa <- cr_journals(query = "economics", limit = 100) %>% .$data %>% as.tibble()

#------ mucha informacion del articulo
aa <- cr_works(dois = my_doi) %>% .$data %>% as.tibble()
```



------------------------------

<br>




## Otros pkg for APIs

<br>

Hay muchos otros paquetes de R hechos para acceder a APIs (twitter, ECB, spotify, pdfetch, naturalearth, ....). Puedes ver algunos [aquí](https://rviews.rstudio.com/2017/11/01/r-data-packages/), [aquí](https://www.r-bloggers.com/r-packages-for-data-access/) y [aquí](https://www.r-bloggers.com/new-data-sources-for-r/).


[Aquí](https://github.com/ropensci/webservices) puedes ver un listado enorrrrrme`r emo::ji("munch")`eeee: Pinterest, Instagram, GoogleTrends, Google Analytics, Flickr, ...., ...., ....


Una de las ultimas que he visto ha sido el pkg [spooc](https://cran.r-project.org/web/packages/spocc/index.html). En su [vignette](https://cran.r-project.org/web/packages/spocc/vignettes/spocc_vignette.html) nos dicen que se pueden acceder a un conjunto de paquetes que contienen: "some form of biodiversity or taxonomic data. Since several of these datasets have been georeferenced, it provides numerous opportunities for visualizing species distributions" 


---------------------

<br>

## Scrapping tables

Además de utilizar paquetes para acceder a servicios web a través de sus APIs, podemos usar otros paquetes (principalmente `rvest`) para hacer web scrapping. Puedes ver ejemplos [aquí](http://zevross.com/blog/2015/05/19/scrape-website-data-with-the-new-r-package-rvest/), [aquí](https://www.r-bloggers.com/fantasy-hockey-with-rvest-and-purrr/), [aquí](https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/) o
[aquí](https://rayms.github.io/2018-01-13-civil-political-rights/).



<br>

[Aquí](https://almeriarusers.wordpress.com/2016/10/11/web-scraping-pca-y-k-means-para-sacar-todo-el-potencial-a-laliga/?utm_source=dlvr.it&utm_medium=twitter) tenéis un ejemplo sencillo para bajar datos de jurgol ... pero ya no funciona

<br>

```{r, echo = TRUE, eval = FALSE}
library(XML)

url <- "http://www.comuniazo.com/comunio/jugadores"
url <- "https://www.comuniazo.com/comunio/jugadores"

jugadores <-  readHTMLTable(url, stringsAsFactors = T, colnames = c("Posicion","Equipo","Jugador","Puntos","Media","Puntos_Casa","Media_Casa","Puntos_Fuera","Media_fuera", "Valor"), colClasses = c("character","character","character","FormattedNumber","FormattedNumber","FormattedNumber","FormattedNumber","FormattedNumber","FormattedNumber"))

aa <- jugadores[[1]] %>% as.tibble()
```




Para sustituir el ejemplo del jurgol bajemos una tabla de la wikipedia. Este ejemplo está sacado de [este post](https://rflowers5.netlify.com/2018/01/17/altitud-de-los-municipios-de-teruel/)


```{r, echo = TRUE, eval = TRUE}
library("rvest")
library("tidyverse")
content <- read_html("https://es.wikipedia.org/wiki/Anexo:Municipios_de_la_provincia_de_Teruel")

body_table <- content %>% html_nodes('body')  %>%
                    html_nodes('table') %>%
                    html_table(dec = ",") 
Teruel <- body_table[[1]]
names(Teruel) <- c("Nombre", "Extension", "Poblacion", "Densidad", "Comarca", "Partido_judicial", "Altitud")
library(stringr)
Teruel <- Teruel %>% map(str_trim) %>% as_tibble() #- quita caracteres al final
Teruel <- Teruel %>% mutate(Altitud = str_replace_all(Altitud,"[[:punct:]]", "")) 
Teruel <- Teruel %>% mutate(Altitud = as.double(Altitud)) %>% arrange(desc(Altitud))
```




```{r}
library(kableExtra)
aa <- Teruel %>% select(1,3,5,7) %>%  slice(1:4) 
#knitr::kable(aa, digits = 2, align = "c", caption = "Los 4 municipios de Teruel con más altitud" )
knitr::kable(aa, "html", digits = 2,  caption = "Los 4 municipios de Teruel con más altitud") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```


<br>

--------------------------------------------

<br>


# Bibliografía

- [This R Data Import Tutorial Is Everything You Need](https://www.datacamp.com/community/tutorials/r-data-import-tutorial#gs.ppa6aFg). Así es como se llama este tutorial de Datacamp. Es sencillo y no muy largo. Tiene muy buena pinta. En general utiliza funciones de base-R. Lo han actualizado hace 4-5 días. No he tenido tiempo de ver que ha cambiado, pero seguro que a mejor.

- La [cheat Sheet de data import de RStudio](https://www.rstudio.com/resources/cheatsheets/). Muy buen resumen/chuleta

- La [sección de importar datos de Quick-R](http://www.statmethods.net/input/importingdata.html). Conciso pero muy claro. Quick-R es muy buen recurso para aprender R.


- [La documentacion oficial](https://cran.r-project.org/doc/manuals/r-release/R-data.html) de R


- [Un post sobre APIs y R](https://www.r-bloggers.com/accessing-apis-from-r-and-a-little-r-programming/). Supongo que complicado.


- Dos post que hacen uso de web scrapping: [este](https://rayms.github.io/2018-01-13-civil-political-rights/)  y [este](https://datascienceplus.com/web-scraping-and-applied-clustering-global-happiness-and-social-progress-index/). También puede que complicado, pero son dos ejemplos de análisis de datos (completo) con R.




